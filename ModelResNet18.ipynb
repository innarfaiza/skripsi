{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ffb277",
   "metadata": {},
   "source": [
    "## ğŸ“š PENJELASAN KONFIGURASI - RESNET18\n",
    "\n",
    "### âš ï¸ CATATAN PENTING\n",
    "**ResNet18 TIDAK tersedia di `tensorflow.keras.applications`!**\n",
    "\n",
    "Notebook ini menggunakan **Custom ResNet18** yang dibangun manual dengan Keras layers.\n",
    "Model ini **TIDAK memiliki pre-trained weights** dari ImageNet.\n",
    "\n",
    "| Model | Parameter | Pre-trained? | Layers |\n",
    "|-------|-----------|--------------|--------|\n",
    "| ResNet18 (Custom) | ~11.2 juta | âŒ Tidak | ~60 |\n",
    "| ResNet50 (Keras) | ~25.6 juta | âœ… Ya | ~175 |\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Label Smoothing\n",
    "Label smoothing mengubah target dari \"keras\" (hard) menjadi \"lembut\" (soft):\n",
    "\n",
    "```\n",
    "TANPA Label Smoothing (Î± = 0):\n",
    "Target Kelas 2: [0, 1, 0, 0]  â† Model DIPAKSA 100% yakin\n",
    "\n",
    "DENGAN Label Smoothing (Î± = 0.1):\n",
    "Target Kelas 2: [0.025, 0.925, 0.025, 0.025]  â† Model BOLEH sedikit ragu\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Class Weights Moderat (Sqrt Balanced)\n",
    "Memberikan bobot berbeda per kelas dalam perhitungan loss:\n",
    "\n",
    "| Kelas | Data Unik | Weight | Efek |\n",
    "|-------|-----------|--------|------|\n",
    "| 1 | 128 | 1.18 | Sedikit boost |\n",
    "| 2 | 256 | 0.83 | Dikurangi (mayoritas) |\n",
    "| 3 | 161 | 1.05 | Hampir netral |\n",
    "| 4 | 63 | 1.67 | Di-boost (minoritas) |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Perbedaan Parameter dengan ResNet50\n",
    "\n",
    "| Parameter | ResNet50 | ResNet18 | Alasan |\n",
    "|-----------|----------|----------|--------|\n",
    "| FINE_TUNE_AT | 140 | 40 | ResNet18 hanya ~60 layers |\n",
    "| LR_PHASE_1 | 1e-4 | 1e-3 | Training from scratch butuh LR lebih tinggi |\n",
    "| LR_PHASE_2 | 5e-5 | 1e-4 | Fine-tuning lebih agresif |\n",
    "| EPOCHS | Lebih sedikit | Lebih banyak | Tanpa pre-trained butuh lebih lama |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e3e0c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "TensorFlow Hub version: 0.16.1\n",
      "GPU Available: []\n",
      "Konfigurasi:\n",
      "  - Image Size: 224x224\n",
      "  - Batch Size: 32\n",
      "  - Num Classes: 4\n",
      "  - Data Path: dataset_final\n",
      "============================================================\n",
      "PROSES PEMUATAN DATASET\n",
      "============================================================\n",
      "\n",
      "[1/3] Memuat dataset_final\\train\n",
      "Found 1400 files belonging to 4 classes.\n",
      "\n",
      "[2/3] Memuat dataset_final\\val\n",
      "Found 131 files belonging to 4 classes.\n",
      "\n",
      "[3/3] Memuat dataset_final\\test\n",
      "Found 132 files belonging to 4 classes.\n",
      "\n",
      "============================================================\n",
      "INFORMASI KELAS & MAPPING\n",
      "============================================================\n",
      "Kelas ditemukan: ['1', '2', '3', '4']\n",
      "\n",
      "Index      | Folder     | Kandungan Aflatoksin\n",
      "--------------------------------------------------\n",
      "0          | 1          | 1 PPB\n",
      "1          | 2          | 2 PPB\n",
      "2          | 3          | 3 PPB\n",
      "3          | 4          | 4 PPB\n",
      "Setting up data augmentation...\n",
      "âœ“ RandomFlip (horizontal)\n",
      "âœ“ RandomRotation (Â±1.6Â°)\n",
      "\n",
      "âŒ RandomBrightness - TIDAK DIGUNAKAN (mengubah nilai PPB)\n",
      "âŒ RandomContrast - TIDAK DIGUNAKAN (mengubah nilai PPB)\n",
      "Fungsi preprocessing untuk ResNet18 telah dibuat.\n",
      "\n",
      "Normalisasi yang digunakan:\n",
      "  - Input: [0, 255]\n",
      "  - Output: [0, 1]\n",
      "Menerapkan preprocessing ke dataset...\n",
      "âœ“ Training dataset: augmentation ON, cache ON, prefetch ON\n",
      "âœ“ Validation dataset: augmentation OFF, cache ON, prefetch ON\n",
      "âœ“ Test dataset: augmentation OFF, cache ON, prefetch ON\n",
      "\n",
      "============================================================\n",
      "PREPROCESSING SELESAI\n",
      "============================================================\n",
      "\n",
      "Dataset siap digunakan untuk training ResNet18!\n",
      "Verifikasi preprocessing...\n",
      "\n",
      "Batch shape: (32, 224, 224, 3)\n",
      "Labels shape: (32, 4)\n",
      "\n",
      "Statistik pixel setelah preprocessing:\n",
      "  - Min: 0.0000\n",
      "  - Max: 0.8309\n",
      "  - Mean: 0.0006\n",
      "  - Std: 0.0107\n",
      "\n",
      "âœ… Range nilai sesuai dengan ekspektasi ResNet18 [0, 1]\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 1. SETUP & LOAD DATA (MENGGUNAKAN PREPROCESS YANG SUDAH ADA)\n",
    "# =================================================================================================\n",
    "\n",
    "# Memanggil file preprocess_resnet18.ipynb agar variabel train_ds, val_ds, test_ds tersedia\n",
    "# Pastikan file preprocess_resnet18.ipynb berada di folder yang sama\n",
    "%run preprocess_resnet18.ipynb\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, GlobalAveragePooling2D, Dropout, Input,\n",
    "    Conv2D, BatchNormalization, Activation, MaxPooling2D, Add\n",
    ")\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import AdamW, SGD, RMSprop, Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class FocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=1.0, gamma=2.0, name='focal_loss'):\n",
    "        super().__init__(name=name)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # Clip predictions\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        # Calculate cross entropy\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        \n",
    "        # Calculate focal weight\n",
    "        pt = y_true * y_pred\n",
    "        pt = tf.reduce_sum(pt, axis=-1, keepdims=True)\n",
    "        focal_weight = tf.pow(1.0 - pt, self.gamma)\n",
    "        \n",
    "        # Apply focal loss\n",
    "        focal_loss = self.alpha * focal_weight * tf.reduce_sum(ce, axis=-1, keepdims=True)\n",
    "        \n",
    "        return tf.reduce_mean(focal_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "resnet18-builder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CUSTOM RESNET18 ARCHITECTURE\n",
      "============================================================\n",
      "\n",
      "Struktur ResNet18:\n",
      "  - Conv1: 7x7, 64 filters, stride 2\n",
      "  - MaxPool: 3x3, stride 2\n",
      "  - Layer1: 2 basic blocks Ã— 64 filters\n",
      "  - Layer2: 2 basic blocks Ã— 128 filters\n",
      "  - Layer3: 2 basic blocks Ã— 256 filters\n",
      "  - Layer4: 2 basic blocks Ã— 512 filters\n",
      "  - Global Average Pooling â†’ 512-dim\n",
      "\n",
      "âœ“ Total layers in base model: 65\n",
      "âœ“ Base model parameters: 11,186,112\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 1.5 CUSTOM RESNET18 BUILDER\n",
    "# =================================================================================================\n",
    "# ResNet18 tidak tersedia di keras.applications, jadi kita bangun manual\n",
    "\n",
    "def basic_block(x, filters, stride=1, downsample=None, name=None):\n",
    "    \"\"\"\n",
    "    Basic Block untuk ResNet18/34\n",
    "    Struktur: x â†’ Conv3x3 â†’ BN â†’ ReLU â†’ Conv3x3 â†’ BN â†’ Add(x) â†’ ReLU\n",
    "    \"\"\"\n",
    "    identity = x\n",
    "    \n",
    "    # First conv\n",
    "    out = Conv2D(filters, 3, strides=stride, padding='same', \n",
    "                 use_bias=False, name=f'{name}_conv1')(x)\n",
    "    out = BatchNormalization(name=f'{name}_bn1')(out)\n",
    "    out = Activation('relu', name=f'{name}_relu1')(out)\n",
    "    \n",
    "    # Second conv\n",
    "    out = Conv2D(filters, 3, strides=1, padding='same', \n",
    "                 use_bias=False, name=f'{name}_conv2')(out)\n",
    "    out = BatchNormalization(name=f'{name}_bn2')(out)\n",
    "    \n",
    "    # Shortcut connection\n",
    "    if downsample is not None:\n",
    "        identity = downsample(x)\n",
    "    \n",
    "    out = Add(name=f'{name}_add')([out, identity])\n",
    "    out = Activation('relu', name=f'{name}_relu2')(out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def make_layer(x, filters, blocks, stride=1, name=None):\n",
    "    \"\"\"\n",
    "    Membuat layer yang terdiri dari beberapa basic blocks\n",
    "    \"\"\"\n",
    "    downsample = None\n",
    "    \n",
    "    # Jika stride != 1 atau jumlah filter berubah, perlu downsample\n",
    "    if stride != 1 or x.shape[-1] != filters:\n",
    "        downsample = Sequential([\n",
    "            Conv2D(filters, 1, strides=stride, use_bias=False),\n",
    "            BatchNormalization()\n",
    "        ], name=f'{name}_downsample')\n",
    "    \n",
    "    # First block (mungkin perlu downsample)\n",
    "    x = basic_block(x, filters, stride, downsample, name=f'{name}_block1')\n",
    "    \n",
    "    # Remaining blocks\n",
    "    for i in range(1, blocks):\n",
    "        x = basic_block(x, filters, name=f'{name}_block{i+1}')\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_resnet18_base(input_shape=(224, 224, 3)):\n",
    "    \"\"\"\n",
    "    Membangun base ResNet18 (tanpa classification head)\n",
    "    \n",
    "    Struktur:\n",
    "    - Conv1: 7x7, 64 filters, stride 2\n",
    "    - MaxPool: 3x3, stride 2  \n",
    "    - Layer1: 2 basic blocks, 64 filters\n",
    "    - Layer2: 2 basic blocks, 128 filters, stride 2\n",
    "    - Layer3: 2 basic blocks, 256 filters, stride 2\n",
    "    - Layer4: 2 basic blocks, 512 filters, stride 2\n",
    "    - Global Average Pooling â†’ Output: 512-dim vector\n",
    "    \n",
    "    Total ~60 layers\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "    \n",
    "    # Initial convolution (conv1)\n",
    "    x = Conv2D(64, 7, strides=2, padding='same', use_bias=False, name='conv1')(inputs)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = Activation('relu', name='relu1')(x)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same', name='maxpool')(x)\n",
    "    \n",
    "    # Residual layers\n",
    "    x = make_layer(x, 64, 2, stride=1, name='layer1')   # conv2_x: 2 blocks\n",
    "    x = make_layer(x, 128, 2, stride=2, name='layer2')  # conv3_x: 2 blocks\n",
    "    x = make_layer(x, 256, 2, stride=2, name='layer3')  # conv4_x: 2 blocks\n",
    "    x = make_layer(x, 512, 2, stride=2, name='layer4')  # conv5_x: 2 blocks\n",
    "    \n",
    "    # Global average pooling\n",
    "    x = GlobalAveragePooling2D(name='avgpool')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x, name='resnet18_base')\n",
    "    return model\n",
    "\n",
    "# Test build dan tampilkan info\n",
    "print(\"=\"*60)\n",
    "print(\"CUSTOM RESNET18 ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nStruktur ResNet18:\")\n",
    "print(\"  - Conv1: 7x7, 64 filters, stride 2\")\n",
    "print(\"  - MaxPool: 3x3, stride 2\")\n",
    "print(\"  - Layer1: 2 basic blocks Ã— 64 filters\")\n",
    "print(\"  - Layer2: 2 basic blocks Ã— 128 filters\")\n",
    "print(\"  - Layer3: 2 basic blocks Ã— 256 filters\")\n",
    "print(\"  - Layer4: 2 basic blocks Ã— 512 filters\")\n",
    "print(\"  - Global Average Pooling â†’ 512-dim\")\n",
    "\n",
    "_test_base = build_resnet18_base()\n",
    "print(f\"\\nâœ“ Total layers in base model: {len(_test_base.layers)}\")\n",
    "print(f\"âœ“ Base model parameters: {_test_base.count_params():,}\")\n",
    "del _test_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e45e610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KONFIGURASI EKSPERIMEN RESNET18\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Arsitektur:\n",
      "   Layer Config: [512, 256]\n",
      "   Dropout: 0.5\n",
      "   Fine-tune at: 20\n",
      "\n",
      "ğŸ“ˆ Phase 1:\n",
      "   LR: 0.001, Epochs: 50\n",
      "\n",
      "ğŸ“ˆ Phase 2:\n",
      "   LR: 0.0005, Epochs: 50\n",
      "\n",
      "âš–ï¸ Class Weights: True\n",
      "   {0: 1.18, 1: 0.83, 2: 1.05, 3: 1.67}\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 2. KONFIGURASI EKSPERIMEN (UBAH PARAMETER DI SINI SETIAP KALI RUNNING)\n",
    "# =================================================================================================\n",
    "# Ini adalah \"Control Panel\" kamu. Ubah angka di sini, lalu Run All.\n",
    "\n",
    "# --- Parameter Arsitektur Model ---\n",
    "LAYER_CONFIG = [512, 256]   # Konfigurasi layer Dense bertingkat\n",
    "                            # Lebih sederhana dari ResNet50 karena model lebih kecil\n",
    "DROPOUT_RATE = 0.5          # 0.5 artinya 50% neuron dimatikan acak saat training\n",
    "FINE_TUNE_AT = 20           # Layer ResNet18 (total ~60) mulai dari mana kita 'cairkan'\n",
    "                            # ResNet18 lebih kecil, jadi fine-tune dari layer lebih awal\n",
    "\n",
    "# --- Parameter Training Phase 1 (Feature Extraction - Base Model Beku) ---\n",
    "LR_PHASE_1 = 1e-3           # Learning Rate lebih tinggi karena training from scratch\n",
    "EPOCHS_PHASE_1 = 50         # Epoch lebih banyak karena tanpa pre-trained weights\n",
    "\n",
    "# --- Parameter Training Phase 2 (Fine Tuning - Base Model Cair Sebagian) ---\n",
    "LR_PHASE_2 = 5e-4           # LR untuk fine-tuning\n",
    "EPOCHS_PHASE_2 = 50         # Epoch lanjutan\n",
    "\n",
    "# --- Lainnya ---\n",
    "BATCH_SIZE = 32             # Jumlah gambar yang diproses sekali jalan\n",
    "OPTIMIZER_NAME = 'Adam'     # Pilihan: 'Adam', 'AdamW', 'SGD', 'RMSprop'\n",
    "LOG_FILE_PATH = 'experiment_log_resnet18.csv'  # Nama file untuk menyimpan hasil\n",
    "MODEL_SAVE_PATH = 'best_resnet18_aflatoxin.keras'\n",
    "\n",
    "# --- Regularisasi ---\n",
    "LABEL_SMOOTHING = 0         # Label smoothing (0 = off)\n",
    "\n",
    "# --- Class Weights Moderat (Sqrt Balanced berdasarkan foto UNIK) ---\n",
    "USE_CLASS_WEIGHTS = True    # Set False jika ingin menonaktifkan\n",
    "CLASS_WEIGHTS = {\n",
    "    0: 1.18,    # Kelas 1 (128 foto unik)\n",
    "    1: 0.83,    # Kelas 2 (256 foto unik)\n",
    "    2: 1.05,    # Kelas 3 (161 foto unik)\n",
    "    3: 1.67,    # Kelas 4 (63 foto unik)\n",
    "}\n",
    "\n",
    "# --- Print Konfigurasi ---\n",
    "print(\"=\"*60)\n",
    "print(\"KONFIGURASI EKSPERIMEN RESNET18\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nğŸ“ Arsitektur:\")\n",
    "print(f\"   Layer Config: {LAYER_CONFIG}\")\n",
    "print(f\"   Dropout: {DROPOUT_RATE}\")\n",
    "print(f\"   Fine-tune at: {FINE_TUNE_AT}\")\n",
    "print(f\"\\nğŸ“ˆ Phase 1:\")\n",
    "print(f\"   LR: {LR_PHASE_1}, Epochs: {EPOCHS_PHASE_1}\")\n",
    "print(f\"\\nğŸ“ˆ Phase 2:\")\n",
    "print(f\"   LR: {LR_PHASE_2}, Epochs: {EPOCHS_PHASE_2}\")\n",
    "print(f\"\\nâš–ï¸ Class Weights: {USE_CLASS_WEIGHTS}\")\n",
    "if USE_CLASS_WEIGHTS:\n",
    "    print(f\"   {CLASS_WEIGHTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "daf83390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Model dibangun dengan Optimizer: Adam | LR Awal: 0.001\n",
      "âœ“ Optimizer: Adam | LR Awal: 0.001\n",
      "âœ“ Loss: Focal Loss (alpha=1.0, gamma=2.0)\n",
      "âœ“ Metrics: accuracy\n",
      "Model compiled successfully!\n",
      "\n",
      "Total parameters: 11,581,124\n",
      "Base model layers: 65\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 3. MEMBANGUN MODEL (ARSITEKTUR RESNET18)\n",
    "# =================================================================================================\n",
    "\n",
    "def build_model_experiment():\n",
    "    # Menggunakan Custom ResNet18 sebagai base\n",
    "    # CATATAN: Tidak ada pre-trained weights!\n",
    "    base_model = build_resnet18_base(input_shape=(224, 224, 3))\n",
    "    \n",
    "    # Freeze Base Model: Kita kunci bobot ResNet agar tidak berubah di Fase 1\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    for units in LAYER_CONFIG:\n",
    "        # Tambah Dense Layer\n",
    "        x = Dense(units, activation='relu')(x)\n",
    "        if DROPOUT_RATE > 0:\n",
    "            x = Dropout(DROPOUT_RATE)(x)\n",
    "    \n",
    "    # Output Layer (4 Kelas)\n",
    "    output = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    return model, base_model\n",
    "\n",
    "# Inisialisasi Model\n",
    "model, base_model = build_model_experiment()\n",
    "\n",
    "# Setup Optimizer Dinamis sesuai Konfigurasi\n",
    "if OPTIMIZER_NAME.lower() == 'adam':\n",
    "    opt = Adam(learning_rate=LR_PHASE_1)\n",
    "elif OPTIMIZER_NAME.lower() == 'sgd':\n",
    "    opt = SGD(learning_rate=LR_PHASE_1, momentum=0.9)\n",
    "elif OPTIMIZER_NAME.lower() == 'adamw':\n",
    "    opt = AdamW(learning_rate=LR_PHASE_1)\n",
    "else:\n",
    "    opt = RMSprop(learning_rate=LR_PHASE_1)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt, \n",
    "    loss=FocalLoss(alpha=1.0, gamma=2.0), \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"\\n[INFO] Model dibangun dengan Optimizer: {OPTIMIZER_NAME} | LR Awal: {LR_PHASE_1}\")\n",
    "print(f\"âœ“ Optimizer: {OPTIMIZER_NAME} | LR Awal: {LR_PHASE_1}\")\n",
    "print(f\"âœ“ Loss: Focal Loss (alpha=1.0, gamma=2.0)\")\n",
    "print(f\"âœ“ Metrics: accuracy\")\n",
    "print(f\"Model compiled successfully!\")\n",
    "print(f\"\\nTotal parameters: {model.count_params():,}\")\n",
    "print(f\"Base model layers: {len(base_model.layers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fcefbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up training callbacks...\n",
      "âœ“ EarlyStopping (monitor='val_accuracy', patience=15)\n",
      "âœ“ ReduceLROnPlateau (factor=0.5, patience=8)\n",
      "âœ“ ModelCheckpoint (save to: best_resnet18_aflatoxin.keras)\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up training callbacks...\")\n",
    "\n",
    "# Training callbacks for better training control\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=20,        # Lebih sabar karena training from scratch\n",
    "        mode='max',\n",
    "        restore_best_weights=True, \n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=8,\n",
    "        min_lr=1e-8,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        MODEL_SAVE_PATH,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"âœ“ EarlyStopping (monitor='val_accuracy', patience=15)\")\n",
    "print(\"âœ“ ReduceLROnPlateau (factor=0.5, patience=8)\")\n",
    "print(f\"âœ“ ModelCheckpoint (save to: {MODEL_SAVE_PATH})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98032e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] === PHASE 1: Training Head Only (50 Epochs) ===\n",
      "âœ“ Class Weights aktif: {0: 1.18, 1: 0.83, 2: 1.05, 3: 1.67}\n",
      "Epoch 1/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.3200 - loss: 0.8835\n",
      "Epoch 1: val_accuracy improved from None to 0.16794, saving model to best_resnet18_aflatoxin.keras\n",
      "\n",
      "Epoch 1: finished saving model to best_resnet18_aflatoxin.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 235ms/step - accuracy: 0.3257 - loss: 0.8762 - val_accuracy: 0.1679 - val_loss: 0.8130 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.3489 - loss: 0.8652\n",
      "Epoch 2: val_accuracy did not improve from 0.16794\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 233ms/step - accuracy: 0.3486 - loss: 0.8625 - val_accuracy: 0.1679 - val_loss: 0.8253 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.3322 - loss: 0.8770\n",
      "Epoch 3: val_accuracy did not improve from 0.16794\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 236ms/step - accuracy: 0.3436 - loss: 0.8697 - val_accuracy: 0.1679 - val_loss: 0.8250 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.3630 - loss: 0.8582\n",
      "Epoch 4: val_accuracy did not improve from 0.16794\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 233ms/step - accuracy: 0.3600 - loss: 0.8543 - val_accuracy: 0.1679 - val_loss: 0.8364 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.3504 - loss: 0.8651\n",
      "Epoch 5: val_accuracy improved from 0.16794 to 0.17557, saving model to best_resnet18_aflatoxin.keras\n",
      "\n",
      "Epoch 5: finished saving model to best_resnet18_aflatoxin.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 242ms/step - accuracy: 0.3450 - loss: 0.8642 - val_accuracy: 0.1756 - val_loss: 0.8000 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.3370 - loss: 0.8576\n",
      "Epoch 6: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 238ms/step - accuracy: 0.3343 - loss: 0.8557 - val_accuracy: 0.1756 - val_loss: 0.8283 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.3317 - loss: 0.8647\n",
      "Epoch 7: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 237ms/step - accuracy: 0.3343 - loss: 0.8598 - val_accuracy: 0.1679 - val_loss: 0.8210 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.3513 - loss: 0.8572\n",
      "Epoch 8: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 243ms/step - accuracy: 0.3486 - loss: 0.8563 - val_accuracy: 0.1679 - val_loss: 0.8235 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.3554 - loss: 0.8515\n",
      "Epoch 9: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 241ms/step - accuracy: 0.3557 - loss: 0.8472 - val_accuracy: 0.1527 - val_loss: 0.8412 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.3641 - loss: 0.8516\n",
      "Epoch 10: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 240ms/step - accuracy: 0.3607 - loss: 0.8484 - val_accuracy: 0.1679 - val_loss: 0.8161 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.3546 - loss: 0.8538\n",
      "Epoch 11: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 239ms/step - accuracy: 0.3486 - loss: 0.8533 - val_accuracy: 0.1450 - val_loss: 0.8239 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.3545 - loss: 0.8579\n",
      "Epoch 12: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 250ms/step - accuracy: 0.3514 - loss: 0.8497 - val_accuracy: 0.1527 - val_loss: 0.8197 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.3525 - loss: 0.8522\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 249ms/step - accuracy: 0.3557 - loss: 0.8473 - val_accuracy: 0.1221 - val_loss: 0.8292 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.3525 - loss: 0.8461\n",
      "Epoch 14: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 239ms/step - accuracy: 0.3493 - loss: 0.8457 - val_accuracy: 0.1603 - val_loss: 0.8069 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.3640 - loss: 0.8372\n",
      "Epoch 15: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 238ms/step - accuracy: 0.3586 - loss: 0.8405 - val_accuracy: 0.1679 - val_loss: 0.8180 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.3779 - loss: 0.8428\n",
      "Epoch 16: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 255ms/step - accuracy: 0.3629 - loss: 0.8422 - val_accuracy: 0.1527 - val_loss: 0.8176 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.3602 - loss: 0.8418\n",
      "Epoch 17: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 258ms/step - accuracy: 0.3486 - loss: 0.8412 - val_accuracy: 0.1527 - val_loss: 0.8094 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.3638 - loss: 0.8390\n",
      "Epoch 18: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 259ms/step - accuracy: 0.3579 - loss: 0.8375 - val_accuracy: 0.1527 - val_loss: 0.8203 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.3736 - loss: 0.8379\n",
      "Epoch 19: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 242ms/step - accuracy: 0.3571 - loss: 0.8409 - val_accuracy: 0.1527 - val_loss: 0.8203 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.3888 - loss: 0.8437\n",
      "Epoch 20: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 238ms/step - accuracy: 0.3764 - loss: 0.8419 - val_accuracy: 0.1527 - val_loss: 0.8142 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.3742 - loss: 0.8393\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.17557\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 233ms/step - accuracy: 0.3679 - loss: 0.8370 - val_accuracy: 0.1603 - val_loss: 0.8140 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.3816 - loss: 0.8337\n",
      "Epoch 22: val_accuracy improved from 0.17557 to 0.18321, saving model to best_resnet18_aflatoxin.keras\n",
      "\n",
      "Epoch 22: finished saving model to best_resnet18_aflatoxin.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 240ms/step - accuracy: 0.3779 - loss: 0.8359 - val_accuracy: 0.1832 - val_loss: 0.8027 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.3619 - loss: 0.8432\n",
      "Epoch 23: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 234ms/step - accuracy: 0.3557 - loss: 0.8407 - val_accuracy: 0.1832 - val_loss: 0.8053 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.3836 - loss: 0.8430\n",
      "Epoch 24: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 233ms/step - accuracy: 0.3671 - loss: 0.8396 - val_accuracy: 0.1603 - val_loss: 0.8059 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.3848 - loss: 0.8328\n",
      "Epoch 25: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 233ms/step - accuracy: 0.3743 - loss: 0.8339 - val_accuracy: 0.1756 - val_loss: 0.8038 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.3776 - loss: 0.8402\n",
      "Epoch 26: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 234ms/step - accuracy: 0.3629 - loss: 0.8365 - val_accuracy: 0.1832 - val_loss: 0.7992 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.3845 - loss: 0.8324\n",
      "Epoch 27: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 236ms/step - accuracy: 0.3671 - loss: 0.8329 - val_accuracy: 0.1679 - val_loss: 0.8066 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.3778 - loss: 0.8382\n",
      "Epoch 28: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 246ms/step - accuracy: 0.3686 - loss: 0.8367 - val_accuracy: 0.1832 - val_loss: 0.8039 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.3817 - loss: 0.8325\n",
      "Epoch 29: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 254ms/step - accuracy: 0.3779 - loss: 0.8288 - val_accuracy: 0.1756 - val_loss: 0.8049 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.3793 - loss: 0.8310\n",
      "Epoch 30: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 246ms/step - accuracy: 0.3657 - loss: 0.8335 - val_accuracy: 0.1679 - val_loss: 0.8026 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.3794 - loss: 0.8375\n",
      "Epoch 31: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 245ms/step - accuracy: 0.3729 - loss: 0.8348 - val_accuracy: 0.1756 - val_loss: 0.8045 - learning_rate: 2.5000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.3719 - loss: 0.8349\n",
      "Epoch 32: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 245ms/step - accuracy: 0.3543 - loss: 0.8369 - val_accuracy: 0.1756 - val_loss: 0.8038 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.3768 - loss: 0.8287\n",
      "Epoch 33: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 246ms/step - accuracy: 0.3714 - loss: 0.8313 - val_accuracy: 0.1756 - val_loss: 0.8064 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.3704 - loss: 0.8354\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 34: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 243ms/step - accuracy: 0.3650 - loss: 0.8351 - val_accuracy: 0.1603 - val_loss: 0.8015 - learning_rate: 2.5000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.3816 - loss: 0.8341\n",
      "Epoch 35: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 244ms/step - accuracy: 0.3671 - loss: 0.8337 - val_accuracy: 0.1679 - val_loss: 0.8058 - learning_rate: 1.2500e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.3896 - loss: 0.8345\n",
      "Epoch 36: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 247ms/step - accuracy: 0.3721 - loss: 0.8347 - val_accuracy: 0.1603 - val_loss: 0.8057 - learning_rate: 1.2500e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.3830 - loss: 0.8270\n",
      "Epoch 37: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 247ms/step - accuracy: 0.3764 - loss: 0.8239 - val_accuracy: 0.1756 - val_loss: 0.8048 - learning_rate: 1.2500e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.3842 - loss: 0.8341\n",
      "Epoch 38: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 250ms/step - accuracy: 0.3729 - loss: 0.8331 - val_accuracy: 0.1679 - val_loss: 0.8083 - learning_rate: 1.2500e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.3742 - loss: 0.8316\n",
      "Epoch 39: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 250ms/step - accuracy: 0.3607 - loss: 0.8314 - val_accuracy: 0.1679 - val_loss: 0.8087 - learning_rate: 1.2500e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.3767 - loss: 0.8341\n",
      "Epoch 40: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 247ms/step - accuracy: 0.3721 - loss: 0.8325 - val_accuracy: 0.1679 - val_loss: 0.8057 - learning_rate: 1.2500e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.3755 - loss: 0.8299\n",
      "Epoch 41: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 246ms/step - accuracy: 0.3664 - loss: 0.8289 - val_accuracy: 0.1756 - val_loss: 0.8056 - learning_rate: 1.2500e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.3850 - loss: 0.8270\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 42: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 244ms/step - accuracy: 0.3750 - loss: 0.8281 - val_accuracy: 0.1679 - val_loss: 0.8083 - learning_rate: 1.2500e-04\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "\n",
      "âœ“ Phase 1 Selesai!\n",
      "âœ“ Best Validation Accuracy Phase 1: 0.1832\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 4. TRAINING PHASE 1 (WARM UP)\n",
    "# =================================================================================================\n",
    "# Tujuannya agar layer Dense baru beradaptasi dengan fitur dari ResNet sebelum ResNet-nya kita utak-atik.\n",
    "\n",
    "active_class_weights = CLASS_WEIGHTS if USE_CLASS_WEIGHTS else None\n",
    "\n",
    "print(f\"\\n[INFO] === PHASE 1: Training Head Only ({EPOCHS_PHASE_1} Epochs) ===\")\n",
    "if USE_CLASS_WEIGHTS:\n",
    "    print(f\"âœ“ Class Weights aktif: {CLASS_WEIGHTS}\")\n",
    "\n",
    "history_1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_PHASE_1,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=active_class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "p1_best_val_acc = max(history_1.history['val_accuracy'])\n",
    "print(f\"\\nâœ“ Phase 1 Selesai!\")\n",
    "print(f\"âœ“ Best Validation Accuracy Phase 1: {p1_best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0dc7314d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bobot terbaik dari Phase 1 berhasil dimuat.\n",
      "\n",
      "[INFO] === PHASE 2: Fine Tuning (Start Layer 20, 50 Epochs) ===\n",
      "âœ“ 45 layers di-unfreeze untuk fine-tuning\n",
      "Epoch 43/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 43: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 596ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 44: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 586ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 45: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 588ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 46: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 590ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 47: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 591ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 48: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 592ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 5.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 49: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 594ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 5.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 50: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 594ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 5.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 51: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 591ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 52: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 597ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 53: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 600ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 54: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 593ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 55: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 595ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 56: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 596ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 57: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 596ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 58: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 591ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 59: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 595ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 1.2500e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 60: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 601ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 1.2500e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 61: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 594ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 1.2500e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step - accuracy: 0.2508 - loss: 14.2817\n",
      "Epoch 62: val_accuracy did not improve from 0.18321\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 600ms/step - accuracy: 0.2500 - loss: 14.2549 - val_accuracy: 0.1069 - val_loss: 14.3955 - learning_rate: 1.2500e-04\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "\n",
      "âœ“ Phase 2 Selesai!\n",
      "âœ“ Best Validation Accuracy Phase 2: 0.1069\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 5. TRAINING PHASE 2 (FINE TUNING)\n",
    "# =================================================================================================\n",
    "# Sekarang kita cairkan sebagian layer ResNet18 untuk menyesuaikan fitur spesifik\n",
    "\n",
    "# --- LANGKAH PENTING: MUAT BOBOT TERBAIK DARI FASE 1 ---\n",
    "try:\n",
    "    model.load_weights(MODEL_SAVE_PATH)\n",
    "    print(\"âœ… Bobot terbaik dari Phase 1 berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Peringatan: Gagal memuat bobot dari {MODEL_SAVE_PATH}. Error: {e}\")\n",
    "    print(\"   Melanjutkan dengan bobot terakhir Phase 1.\")\n",
    "    \n",
    "print(f\"\\n[INFO] === PHASE 2: Fine Tuning (Start Layer {FINE_TUNE_AT}, {EPOCHS_PHASE_2} Epochs) ===\")\n",
    "\n",
    "total_epochs = EPOCHS_PHASE_1 + EPOCHS_PHASE_2\n",
    "base_model.trainable = True  # Unfreeze base model\n",
    "\n",
    "# Freeze ulang layer-layer awal (Low-level features seperti garis/sudut biasanya sudah bagus)\n",
    "# Kita hanya ingin melatih layer-layer akhir (High-level features)\n",
    "for layer in base_model.layers[:FINE_TUNE_AT]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Hitung jumlah layer yang di-unfreeze\n",
    "trainable_count = sum([1 for layer in base_model.layers if layer.trainable])\n",
    "print(f\"âœ“ {trainable_count} layers di-unfreeze untuk fine-tuning\")\n",
    "\n",
    "# Compile ulang wajib dilakukan setelah mengubah trainable status\n",
    "# Gunakan LR yang lebih kecil untuk fine-tuning\n",
    "if OPTIMIZER_NAME.lower() == 'adam':\n",
    "    opt_ft = Adam(learning_rate=LR_PHASE_2)\n",
    "elif OPTIMIZER_NAME.lower() == 'sgd':\n",
    "    opt_ft = SGD(learning_rate=LR_PHASE_2, momentum=0.9)\n",
    "elif OPTIMIZER_NAME.lower() == 'adamw':\n",
    "    opt_ft = AdamW(learning_rate=LR_PHASE_2)\n",
    "else:\n",
    "    opt_ft = RMSprop(learning_rate=LR_PHASE_2)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt_ft, \n",
    "    loss=FocalLoss(alpha=1.0, gamma=2.0), \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "history_2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    initial_epoch=len(history_1.history['loss']),\n",
    "    epochs=total_epochs,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=active_class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "p2_best_val_acc = max(history_2.history['val_accuracy'])\n",
    "print(f\"\\nâœ“ Phase 2 Selesai!\")\n",
    "print(f\"âœ“ Best Validation Accuracy Phase 2: {p2_best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Melakukan Evaluasi Menyeluruh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 102 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Best model loaded from best_resnet18_aflatoxin.keras\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000028812A57100> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 197ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000028812A57100> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  3  1 14]\n",
      " [ 4  4  5 42]\n",
      " [ 2  1  3 29]\n",
      " [ 1  0  1 12]]\n",
      "============================================================\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kelas 1     0.5882    0.3571    0.4444        28\n",
      "     Kelas 2     0.5000    0.0727    0.1270        55\n",
      "     Kelas 3     0.3000    0.0857    0.1333        35\n",
      "     Kelas 4     0.1237    0.8571    0.2162        14\n",
      "\n",
      "    accuracy                         0.2197       132\n",
      "   macro avg     0.3780    0.3432    0.2302       132\n",
      "weighted avg     0.4258    0.2197    0.2055       132\n",
      "\n",
      "âœ… Akurasi Test Akhir: 21.97%\n",
      "âœ… Rata-rata Confidence: 33.08%\n",
      "\n",
      "ğŸ–¼ï¸ Gambar Confusion Matrix tersimpan di: history_plots\\cm_resnet18_20260130_221851_Acc22.0.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 6. EVALUASI DAN METRIK (OTOMATIS)\n",
    "# =================================================================================================\n",
    "print(\"\\n[INFO] Melakukan Evaluasi Menyeluruh...\")\n",
    "\n",
    "# Load best model\n",
    "try:\n",
    "    model.load_weights(MODEL_SAVE_PATH)\n",
    "    print(f\"âœ“ Best model loaded from {MODEL_SAVE_PATH}\")\n",
    "except:\n",
    "    print(\"âš ï¸ Using current model weights\")\n",
    "\n",
    "# Prediksi (menghasilkan probabilitas, misal [0.1, 0.8, 0.05, 0.05])\n",
    "Y_pred_probs = model.predict(test_ds, verbose=1)\n",
    "\n",
    "# Ambil kelas dengan probabilitas tertinggi\n",
    "y_pred = np.argmax(Y_pred_probs, axis=1)\n",
    "\n",
    "# Label asli (Ground Truth)\n",
    "y_true_onehot = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "y_true = np.argmax(y_true_onehot, axis=1)\n",
    "\n",
    "class_names = ['Kelas 1', 'Kelas 2', 'Kelas 3', 'Kelas 4']\n",
    "\n",
    "# --- Metrik 1: Akurasi Global ---\n",
    "test_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# --- Metrik 2: Confusion Matrix ---\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_str = str(cm.tolist())\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# --- Metrik 3: Confidence Statistics ---\n",
    "confidence_scores = np.max(Y_pred_probs, axis=1)\n",
    "avg_conf = np.mean(confidence_scores)\n",
    "min_conf = np.min(confidence_scores)\n",
    "std_conf = np.std(confidence_scores)\n",
    "\n",
    "# --- Metrik 4: Precision, Recall, F1 Per Kelas ---\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, digits=4, output_dict=True)\n",
    "print(\"=\" * 60)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "print(f\"âœ… Akurasi Test Akhir: {test_acc*100:.2f}%\")\n",
    "print(f\"âœ… Rata-rata Confidence: {avg_conf*100:.2f}%\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plot_folder = \"history_plots_RN18\" \n",
    "if not os.path.exists(plot_folder):\n",
    "    os.makedirs(plot_folder)\n",
    "\n",
    "current_time_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "plot_filename = f\"cm_resnet18_{current_time_str}_Acc{test_acc*100:.1f}.png\"\n",
    "plot_filepath = os.path.join(plot_folder, plot_filename)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            annot_kws={\"size\": 14})\n",
    "plt.title(f'Confusion Matrix - ResNet18 (Acc: {test_acc*100:.2f}%)')\n",
    "plt.ylabel('Actual Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(plot_filepath, dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nğŸ–¼ï¸ Gambar Confusion Matrix tersimpan di: {plot_filepath}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f7be1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SAVE] Hasil percobaan berhasil ditambahkan ke: experiment_log_resnet18.csv\n",
      "============================================================\n",
      "PROSES SELESAI. SILAKAN UBAH PARAMETER DI ATAS UNTUK PERCOBAAN BERIKUTNYA.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 7. SISTEM PENYIMPANAN LOG (AUTO-CSV)\n",
    "# =================================================================================================\n",
    "# Bagian ini yang akan menyimpan \"Jejak Percobaan\" kamu selamanya.\n",
    "\n",
    "# Dictionary data untuk satu baris CSV\n",
    "log_data = {\n",
    "    # Waktu\n",
    "    \"Timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \n",
    "    # Model Info\n",
    "    \"Model\": \"ResNet18 (Custom)\",\n",
    "    \n",
    "    # Parameter Setup\n",
    "    \"Optimizer\": OPTIMIZER_NAME,\n",
    "    \"Batch_Size\": BATCH_SIZE,\n",
    "    \"Layer_Config\": str(LAYER_CONFIG),\n",
    "    \"Dropout\": DROPOUT_RATE,\n",
    "    \"Fine_Tune_At\": FINE_TUNE_AT,\n",
    "    \n",
    "    # Parameter Training\n",
    "    \"LR_Phase_1\": LR_PHASE_1,\n",
    "    \"Epochs_P1\": EPOCHS_PHASE_1,\n",
    "    \"LR_Phase_2\": LR_PHASE_2,\n",
    "    \"Epochs_P2\": EPOCHS_PHASE_2,\n",
    "    \"Label_Smoothing\": LABEL_SMOOTHING,\n",
    "    \"Use_Class_Weights\": USE_CLASS_WEIGHTS,\n",
    "    \n",
    "    # Hasil Evaluasi Global\n",
    "    \"Accuracy\": round(test_acc, 4),\n",
    "    \"Val_Acc_P1\": round(p1_best_val_acc, 4),\n",
    "    \"Val_Acc_P2\": round(p2_best_val_acc, 4),\n",
    "    \"Avg_Confidence\": round(avg_conf, 4),\n",
    "    \"Min_Confidence\": round(min_conf, 4),\n",
    "    \"Std_Confidence\": round(std_conf, 4),\n",
    "    \"Confusion_Matrix\": cm_str\n",
    "}\n",
    "\n",
    "# Loop otomatis untuk mengambil Precision/Recall/F1 tiap kelas\n",
    "for label in class_names:\n",
    "    metrics = report[label]\n",
    "    log_data[f\"Class_{label}_Prec\"] = round(metrics['precision'], 4)\n",
    "    log_data[f\"Class_{label}_Rec\"] = round(metrics['recall'], 4)\n",
    "    log_data[f\"Class_{label}_F1\"] = round(metrics['f1-score'], 4)\n",
    "\n",
    "# Buat DataFrame (1 baris)\n",
    "df_new_log = pd.DataFrame([log_data])\n",
    "\n",
    "# Logika Penyimpanan: Append jika file ada, Write jika belum ada\n",
    "if not os.path.exists(LOG_FILE_PATH):\n",
    "    df_new_log.to_csv(LOG_FILE_PATH, index=False)\n",
    "    print(f\"\\n[SAVE] File log baru dibuat: {LOG_FILE_PATH}\")\n",
    "else:\n",
    "    df_new_log.to_csv(LOG_FILE_PATH, mode='a', header=False, index=False)\n",
    "    print(f\"\\n[SAVE] Hasil percobaan berhasil ditambahkan ke: {LOG_FILE_PATH}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PROSES SELESAI. SILAKAN UBAH PARAMETER DI ATAS UNTUK PERCOBAAN BERIKUTNYA.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f6f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589e1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
