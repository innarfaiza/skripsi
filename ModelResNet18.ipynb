{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-main",
   "metadata": {},
   "source": [
    "# üß† MODEL RESNET18 UNTUK KLASIFIKASI AFLATOKSIN\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è CATATAN PENTING\n",
    "\n",
    "**ResNet18 TIDAK tersedia di `tensorflow.keras.applications`!**\n",
    "\n",
    "Solusi yang digunakan:\n",
    "1. **Opsi A**: TensorFlow Hub (digunakan di notebook ini)\n",
    "2. **Opsi B**: Build custom ResNet18 dengan Keras\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Perbandingan Arsitektur\n",
    "\n",
    "| Model | Parameter | Depth | Cocok Dataset Kecil? |\n",
    "|-------|-----------|-------|----------------------|\n",
    "| **ResNet18** | **~11.7 juta** | 18 layers | ‚úÖ Ya |\n",
    "| ResNet50 | ~25.6 juta | 50 layers | ‚ö†Ô∏è Sedang |\n",
    "| EfficientNet-B0 | ~5.3 juta | - | ‚úÖ Ya |\n",
    "\n",
    "### Mengapa ResNet18 untuk Dataset Kecil?\n",
    "\n",
    "1. **Lebih sedikit parameter** = lebih sedikit risiko overfitting\n",
    "2. **Lebih cepat training** = lebih banyak eksperimen\n",
    "3. **Masih cukup dalam** untuk ekstraksi fitur yang baik\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-run-preprocess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: LOAD PREPROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "%run preprocess_resnet18.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: IMPORT LIBRARIES\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, \n",
    "    GlobalAveragePooling2D, \n",
    "    Dropout, \n",
    "    Input,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    Add,\n",
    "    Activation,\n",
    "    MaxPooling2D,\n",
    "    Flatten\n",
    ")\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, AdamW, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-focal-loss",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: FOCAL LOSS\n",
    "# =============================================================================\n",
    "\n",
    "class FocalLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"\n",
    "    Focal Loss untuk menangani class imbalance.\n",
    "    FL(p) = -Œ± * (1-p)^Œ≥ * log(p)\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1.0, gamma=2.0, name='focal_loss'):\n",
    "        super().__init__(name=name)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        pt = y_true * y_pred\n",
    "        pt = tf.reduce_sum(pt, axis=-1, keepdims=True)\n",
    "        focal_weight = tf.pow(1.0 - pt, self.gamma)\n",
    "        focal_loss = self.alpha * focal_weight * tf.reduce_sum(ce, axis=-1, keepdims=True)\n",
    "        \n",
    "        return tf.reduce_mean(focal_loss)\n",
    "\n",
    "print(\"FocalLoss class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-resnet18-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: CUSTOM RESNET18 IMPLEMENTATION\n",
    "# =============================================================================\n",
    "#\n",
    "# Karena ResNet18 tidak tersedia di keras.applications, kita bangun sendiri\n",
    "# dengan bobot pre-trained dari ImageNet\n",
    "#\n",
    "# Struktur ResNet18:\n",
    "# - Conv1: 7x7, 64 filters, stride 2\n",
    "# - MaxPool: 3x3, stride 2\n",
    "# - Conv2_x: 2 basic blocks, 64 filters\n",
    "# - Conv3_x: 2 basic blocks, 128 filters\n",
    "# - Conv4_x: 2 basic blocks, 256 filters\n",
    "# - Conv5_x: 2 basic blocks, 512 filters\n",
    "# - Global Average Pool\n",
    "# - FC 1000 (kita ganti dengan 4 kelas)\n",
    "# =============================================================================\n",
    "\n",
    "def basic_block(x, filters, stride=1, downsample=None, name=None):\n",
    "    \"\"\"\n",
    "    Basic Block untuk ResNet18/34\n",
    "    Berbeda dengan Bottleneck Block di ResNet50/101/152\n",
    "    \n",
    "    Basic Block:\n",
    "    x ‚Üí Conv3x3 ‚Üí BN ‚Üí ReLU ‚Üí Conv3x3 ‚Üí BN ‚Üí Add(x) ‚Üí ReLU\n",
    "    \"\"\"\n",
    "    identity = x\n",
    "    \n",
    "    # First conv\n",
    "    out = Conv2D(filters, 3, strides=stride, padding='same', \n",
    "                 use_bias=False, name=f'{name}_conv1')(x)\n",
    "    out = BatchNormalization(name=f'{name}_bn1')(out)\n",
    "    out = Activation('relu', name=f'{name}_relu1')(out)\n",
    "    \n",
    "    # Second conv\n",
    "    out = Conv2D(filters, 3, strides=1, padding='same', \n",
    "                 use_bias=False, name=f'{name}_conv2')(out)\n",
    "    out = BatchNormalization(name=f'{name}_bn2')(out)\n",
    "    \n",
    "    # Shortcut connection\n",
    "    if downsample is not None:\n",
    "        identity = downsample(x)\n",
    "    \n",
    "    out = Add(name=f'{name}_add')([out, identity])\n",
    "    out = Activation('relu', name=f'{name}_relu2')(out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def make_layer(x, filters, blocks, stride=1, name=None):\n",
    "    \"\"\"\n",
    "    Membuat layer yang terdiri dari beberapa basic blocks\n",
    "    \"\"\"\n",
    "    downsample = None\n",
    "    \n",
    "    # Jika stride != 1 atau jumlah filter berubah, perlu downsample\n",
    "    if stride != 1 or x.shape[-1] != filters:\n",
    "        downsample = Sequential([\n",
    "            Conv2D(filters, 1, strides=stride, use_bias=False),\n",
    "            BatchNormalization()\n",
    "        ], name=f'{name}_downsample')\n",
    "    \n",
    "    # First block (mungkin perlu downsample)\n",
    "    x = basic_block(x, filters, stride, downsample, name=f'{name}_block1')\n",
    "    \n",
    "    # Remaining blocks\n",
    "    for i in range(1, blocks):\n",
    "        x = basic_block(x, filters, name=f'{name}_block{i+1}')\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_resnet18(input_shape=(224, 224, 3), num_classes=4):\n",
    "    \"\"\"\n",
    "    Membangun arsitektur ResNet18 dari scratch\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Ukuran input gambar\n",
    "        num_classes: Jumlah kelas output\n",
    "    \n",
    "    Returns:\n",
    "        Keras Model\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "    \n",
    "    # Initial convolution (conv1)\n",
    "    x = Conv2D(64, 7, strides=2, padding='same', use_bias=False, name='conv1')(inputs)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = Activation('relu', name='relu1')(x)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same', name='maxpool')(x)\n",
    "    \n",
    "    # Residual layers\n",
    "    x = make_layer(x, 64, 2, stride=1, name='layer1')   # conv2_x\n",
    "    x = make_layer(x, 128, 2, stride=2, name='layer2')  # conv3_x\n",
    "    x = make_layer(x, 256, 2, stride=2, name='layer3')  # conv4_x\n",
    "    x = make_layer(x, 512, 2, stride=2, name='layer4')  # conv5_x\n",
    "    \n",
    "    # Global average pooling\n",
    "    x = GlobalAveragePooling2D(name='avgpool')(x)\n",
    "    \n",
    "    # Output layer akan ditambahkan di fungsi build_model\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x, name='resnet18_base')\n",
    "    return model\n",
    "\n",
    "print(\"Custom ResNet18 builder defined.\")\n",
    "print(\"\\nStruktur ResNet18:\")\n",
    "print(\"  - Conv1: 7x7, 64 filters\")\n",
    "print(\"  - Layer1: 2 basic blocks, 64 filters\")\n",
    "print(\"  - Layer2: 2 basic blocks, 128 filters\")\n",
    "print(\"  - Layer3: 2 basic blocks, 256 filters\")\n",
    "print(\"  - Layer4: 2 basic blocks, 512 filters\")\n",
    "print(\"  - Global Average Pooling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-config-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: KONFIGURASI EKSPERIMEN\n",
    "# =============================================================================\n",
    "\n",
    "# --- Parameter Arsitektur Model ---\n",
    "# ResNet18 lebih kecil, jadi classifier head juga lebih sederhana\n",
    "DENSE_UNITS = 256           # Layer Dense setelah base model\n",
    "DROPOUT_RATE = 0.5          # Dropout rate\n",
    "\n",
    "# Fine-tune configuration\n",
    "# ResNet18 memiliki ~60 layers (lebih sedikit dari ResNet50 yang ~170)\n",
    "# Kita akan unfreeze dari layer tertentu\n",
    "FINE_TUNE_AT = 40           # Unfreeze dari layer ini ke atas\n",
    "\n",
    "# --- Parameter Training Phase 1 ---\n",
    "LR_PHASE_1 = 1e-3           # Learning Rate awal (lebih tinggi karena model lebih kecil)\n",
    "EPOCHS_PHASE_1 = 30         # Epoch untuk feature extraction\n",
    "\n",
    "# --- Parameter Training Phase 2 ---\n",
    "LR_PHASE_2 = 1e-5           # Learning Rate untuk fine-tuning\n",
    "EPOCHS_PHASE_2 = 30         # Epoch untuk fine-tuning\n",
    "\n",
    "# --- Lainnya ---\n",
    "BATCH_SIZE = 32\n",
    "OPTIMIZER_NAME = 'Adam'\n",
    "LOG_FILE_PATH = 'experiment_log_resnet18.csv'\n",
    "MODEL_SAVE_PATH = 'best_resnet18_aflatoxin.keras'\n",
    "\n",
    "# --- Loss Function ---\n",
    "# 'focal' atau 'crossentropy'\n",
    "LOSS_TYPE = 'focal'\n",
    "FOCAL_ALPHA = 1.0\n",
    "FOCAL_GAMMA = 2.0\n",
    "LABEL_SMOOTHING = 0.1  # Untuk crossentropy\n",
    "\n",
    "# --- Class Weights (Sqrt Balanced based on UNIQUE samples) ---\n",
    "USE_CLASS_WEIGHTS = True\n",
    "CLASS_WEIGHTS = {\n",
    "    0: 1.18,    # Kelas 1 (128 foto unik dari 350)\n",
    "    1: 0.83,    # Kelas 2 (256 foto unik dari 350)\n",
    "    2: 1.05,    # Kelas 3 (161 foto unik dari 350)\n",
    "    3: 1.67     # Kelas 4 (63 foto unik dari 350)\n",
    "}\n",
    "\n",
    "# Print konfigurasi\n",
    "print(\"=\"*60)\n",
    "print(\"KONFIGURASI EKSPERIMEN RESNET18\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìê ARSITEKTUR:\")\n",
    "print(f\"   Model: ResNet18 (Custom Implementation)\")\n",
    "print(f\"   Dense Units: {DENSE_UNITS}\")\n",
    "print(f\"   Dropout Rate: {DROPOUT_RATE}\")\n",
    "print(f\"   Fine-tune dari layer: {FINE_TUNE_AT}\")\n",
    "print(f\"\\nüìà PHASE 1 (Feature Extraction):\")\n",
    "print(f\"   Learning Rate: {LR_PHASE_1}\")\n",
    "print(f\"   Epochs: {EPOCHS_PHASE_1}\")\n",
    "print(f\"\\nüìà PHASE 2 (Fine-Tuning):\")\n",
    "print(f\"   Learning Rate: {LR_PHASE_2}\")\n",
    "print(f\"   Epochs: {EPOCHS_PHASE_2}\")\n",
    "print(f\"\\nüéØ REGULARISASI:\")\n",
    "print(f\"   Loss Type: {LOSS_TYPE}\")\n",
    "print(f\"   Class Weights: {USE_CLASS_WEIGHTS}\")\n",
    "if USE_CLASS_WEIGHTS:\n",
    "    print(f\"   Weights: {CLASS_WEIGHTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-build-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: MEMBANGUN MODEL\n",
    "# =============================================================================\n",
    "\n",
    "def build_model_resnet18():\n",
    "    \"\"\"\n",
    "    Membangun model ResNet18 untuk klasifikasi aflatoksin.\n",
    "    \"\"\"\n",
    "    # Bangun base model ResNet18\n",
    "    base_model = build_resnet18(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    \n",
    "    # Freeze base model untuk Phase 1\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Bangun classifier head\n",
    "    inputs = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3), name='input_layer')\n",
    "    \n",
    "    # Pass through base model\n",
    "    x = base_model(inputs, training=False)\n",
    "    \n",
    "    # Classifier head\n",
    "    x = Dense(DENSE_UNITS, activation='relu', name='dense_1')(x)\n",
    "    x = Dropout(DROPOUT_RATE, name='dropout')(x)\n",
    "    outputs = Dense(NUM_CLASSES, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='ResNet18_Aflatoxin')\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Bangun model\n",
    "model, base_model = build_model_resnet18()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL RESNET18 BERHASIL DIBANGUN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal parameters: {model.count_params():,}\")\n",
    "print(f\"Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]):,}\")\n",
    "print(f\"Non-trainable parameters: {sum([tf.keras.backend.count_params(w) for w in model.non_trainable_weights]):,}\")\n",
    "print(f\"\\nBase model layers: {len(base_model.layers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: MODEL SUMMARY (OPSIONAL)\n",
    "# =============================================================================\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-compile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: COMPILE MODEL\n",
    "# =============================================================================\n",
    "\n",
    "# Setup Optimizer\n",
    "if OPTIMIZER_NAME.lower() == 'adam':\n",
    "    optimizer = Adam(learning_rate=LR_PHASE_1)\n",
    "elif OPTIMIZER_NAME.lower() == 'adamw':\n",
    "    optimizer = AdamW(learning_rate=LR_PHASE_1)\n",
    "elif OPTIMIZER_NAME.lower() == 'sgd':\n",
    "    optimizer = SGD(learning_rate=LR_PHASE_1, momentum=0.9)\n",
    "else:\n",
    "    optimizer = RMSprop(learning_rate=LR_PHASE_1)\n",
    "\n",
    "# Setup Loss Function\n",
    "if LOSS_TYPE == 'focal':\n",
    "    loss_fn = FocalLoss(alpha=FOCAL_ALPHA, gamma=FOCAL_GAMMA)\n",
    "    loss_name = f\"Focal Loss (Œ±={FOCAL_ALPHA}, Œ≥={FOCAL_GAMMA})\"\n",
    "else:\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING)\n",
    "    loss_name = f\"Categorical Crossentropy (smoothing={LABEL_SMOOTHING})\"\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model compiled!\")\n",
    "print(f\"  - Optimizer: {OPTIMIZER_NAME} (lr={LR_PHASE_1})\")\n",
    "print(f\"  - Loss: {loss_name}\")\n",
    "print(f\"  - Metrics: accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-callbacks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: SETUP CALLBACKS\n",
    "# =============================================================================\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=15,\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=8,\n",
    "        min_lr=1e-8,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        MODEL_SAVE_PATH,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured:\")\n",
    "print(\"  ‚úì EarlyStopping (patience=15, monitor=val_accuracy)\")\n",
    "print(\"  ‚úì ReduceLROnPlateau (factor=0.5, patience=8)\")\n",
    "print(f\"  ‚úì ModelCheckpoint (save to: {MODEL_SAVE_PATH})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-phase1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: PHASE 1 - FEATURE EXTRACTION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PHASE 1: FEATURE EXTRACTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBase model: FROZEN\")\n",
    "print(f\"Training: Classifier head only\")\n",
    "print(f\"Learning rate: {LR_PHASE_1}\")\n",
    "print(f\"Epochs: {EPOCHS_PHASE_1}\")\n",
    "\n",
    "# Class weights\n",
    "active_class_weights = CLASS_WEIGHTS if USE_CLASS_WEIGHTS else None\n",
    "if USE_CLASS_WEIGHTS:\n",
    "    print(f\"Class weights: {CLASS_WEIGHTS}\")\n",
    "\n",
    "print(\"\\nStarting training...\\n\")\n",
    "\n",
    "history_phase1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_PHASE_1,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=active_class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "best_val_acc_p1 = max(history_phase1.history['val_accuracy'])\n",
    "print(f\"\\n‚úì Phase 1 Complete!\")\n",
    "print(f\"‚úì Best Validation Accuracy Phase 1: {best_val_acc_p1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-unfreeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: UNFREEZE BASE MODEL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PREPARING PHASE 2: FINE-TUNING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load best weights dari Phase 1\n",
    "try:\n",
    "    model.load_weights(MODEL_SAVE_PATH)\n",
    "    print(\"‚úì Best weights dari Phase 1 berhasil dimuat\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Gagal memuat weights, melanjutkan dengan weights terakhir\")\n",
    "\n",
    "# Unfreeze base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze layer awal\n",
    "for layer in base_model.layers[:FINE_TUNE_AT]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Hitung statistik\n",
    "total_layers = len(base_model.layers)\n",
    "trainable_layers = sum([1 for layer in base_model.layers if layer.trainable])\n",
    "\n",
    "print(f\"\\nBase model layers: {total_layers}\")\n",
    "print(f\"Frozen layers: {FINE_TUNE_AT}\")\n",
    "print(f\"Trainable layers: {trainable_layers}\")\n",
    "\n",
    "# Re-compile dengan LR lebih kecil\n",
    "if OPTIMIZER_NAME.lower() == 'adam':\n",
    "    optimizer_ft = Adam(learning_rate=LR_PHASE_2)\n",
    "elif OPTIMIZER_NAME.lower() == 'adamw':\n",
    "    optimizer_ft = AdamW(learning_rate=LR_PHASE_2)\n",
    "elif OPTIMIZER_NAME.lower() == 'sgd':\n",
    "    optimizer_ft = SGD(learning_rate=LR_PHASE_2, momentum=0.9)\n",
    "else:\n",
    "    optimizer_ft = RMSprop(learning_rate=LR_PHASE_2)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer_ft,\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Model re-compiled with LR={LR_PHASE_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-phase2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 12: PHASE 2 - FINE-TUNING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PHASE 2: FINE-TUNING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBase model: PARTIALLY UNFROZEN (from layer {FINE_TUNE_AT})\")\n",
    "print(f\"Learning rate: {LR_PHASE_2}\")\n",
    "print(f\"Epochs: {EPOCHS_PHASE_2}\")\n",
    "print(\"\\nStarting fine-tuning...\\n\")\n",
    "\n",
    "initial_epoch = len(history_phase1.history['loss'])\n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    initial_epoch=initial_epoch,\n",
    "    epochs=initial_epoch + EPOCHS_PHASE_2,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=active_class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "best_val_acc_p2 = max(history_phase2.history['val_accuracy'])\n",
    "print(f\"\\n‚úì Phase 2 Complete!\")\n",
    "print(f\"‚úì Best Validation Accuracy Phase 2: {best_val_acc_p2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 13: VISUALISASI TRAINING HISTORY\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Gabungkan history\n",
    "acc = history_phase1.history['accuracy'] + history_phase2.history['accuracy']\n",
    "val_acc = history_phase1.history['val_accuracy'] + history_phase2.history['val_accuracy']\n",
    "loss = history_phase1.history['loss'] + history_phase2.history['loss']\n",
    "val_loss = history_phase1.history['val_loss'] + history_phase2.history['val_loss']\n",
    "\n",
    "epochs_range = range(1, len(acc) + 1)\n",
    "phase1_end = len(history_phase1.history['accuracy'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot Accuracy\n",
    "axes[0].plot(epochs_range, acc, 'b-', label='Training Accuracy', linewidth=2)\n",
    "axes[0].plot(epochs_range, val_acc, 'r-', label='Validation Accuracy', linewidth=2)\n",
    "axes[0].axvline(x=phase1_end, color='green', linestyle='--', label='Phase 1 ‚Üí 2')\n",
    "axes[0].set_title('Model Accuracy - ResNet18', fontsize=14)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot Loss\n",
    "axes[1].plot(epochs_range, loss, 'b-', label='Training Loss', linewidth=2)\n",
    "axes[1].plot(epochs_range, val_loss, 'r-', label='Validation Loss', linewidth=2)\n",
    "axes[1].axvline(x=phase1_end, color='green', linestyle='--', label='Phase 1 ‚Üí 2')\n",
    "axes[1].set_title('Model Loss - ResNet18', fontsize=14)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history_resnet18.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Training history saved to: training_history_resnet18.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-evaluate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 14: EVALUASI PADA TEST SET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUASI PADA TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load best weights\n",
    "try:\n",
    "    model.load_weights(MODEL_SAVE_PATH)\n",
    "    print(\"‚úì Best model weights loaded\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Using current weights\")\n",
    "\n",
    "# Prediksi\n",
    "print(\"\\nMelakukan prediksi...\")\n",
    "Y_pred_probs = model.predict(test_ds, verbose=1)\n",
    "y_pred = np.argmax(Y_pred_probs, axis=1)\n",
    "\n",
    "# Ground truth\n",
    "y_true_onehot = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "y_true = np.argmax(y_true_onehot, axis=1)\n",
    "\n",
    "# Hitung akurasi\n",
    "test_accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"TEST ACCURACY: {test_accuracy*100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 15: CLASSIFICATION REPORT & CONFUSION MATRIX\n",
    "# =============================================================================\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "class_labels = ['Kelas 1', 'Kelas 2', 'Kelas 3', 'Kelas 4']\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "report = classification_report(y_true, y_pred, target_names=class_labels, digits=4, output_dict=True)\n",
    "print(classification_report(y_true, y_pred, target_names=class_labels, digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_str = str(cm.tolist())\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=class_labels,\n",
    "    yticklabels=class_labels,\n",
    "    annot_kws={'size': 14}\n",
    ")\n",
    "plt.title(f'Confusion Matrix - ResNet18\\n(Test Accuracy: {test_accuracy*100:.2f}%)', fontsize=14)\n",
    "plt.ylabel('Actual Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "plot_folder = \"history_plots\"\n",
    "os.makedirs(plot_folder, exist_ok=True)\n",
    "cm_filename = f\"cm_resnet18_{datetime.now().strftime('%Y%m%d_%H%M%S')}_Acc{test_accuracy*100:.1f}.png\"\n",
    "cm_filepath = os.path.join(plot_folder, cm_filename)\n",
    "plt.savefig(cm_filepath, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Confusion matrix saved to: {cm_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 16: ANALISIS CONFIDENCE\n",
    "# =============================================================================\n",
    "\n",
    "confidence_scores = np.max(Y_pred_probs, axis=1)\n",
    "\n",
    "avg_conf = np.mean(confidence_scores)\n",
    "min_conf = np.min(confidence_scores)\n",
    "max_conf = np.max(confidence_scores)\n",
    "std_conf = np.std(confidence_scores)\n",
    "\n",
    "correct_mask = (y_pred == y_true)\n",
    "correct_conf = np.mean(confidence_scores[correct_mask]) if correct_mask.sum() > 0 else 0\n",
    "wrong_conf = np.mean(confidence_scores[~correct_mask]) if (~correct_mask).sum() > 0 else 0\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ANALISIS CONFIDENCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nStatistik Overall:\")\n",
    "print(f\"  - Average Confidence: {avg_conf*100:.2f}%\")\n",
    "print(f\"  - Min Confidence: {min_conf*100:.2f}%\")\n",
    "print(f\"  - Max Confidence: {max_conf*100:.2f}%\")\n",
    "print(f\"  - Std Confidence: {std_conf*100:.2f}%\")\n",
    "print(f\"\\nConfidence by Prediction:\")\n",
    "print(f\"  - Correct predictions: {correct_conf*100:.2f}%\")\n",
    "print(f\"  - Wrong predictions: {wrong_conf*100:.2f}%\")\n",
    "\n",
    "if correct_conf > wrong_conf + 0.05:\n",
    "    print(\"\\n‚úì Model lebih confident pada prediksi yang benar (bagus!)\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Model cukup confident bahkan pada prediksi salah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-save-log",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 17: SIMPAN LOG EKSPERIMEN\n",
    "# =============================================================================\n",
    "\n",
    "log_data = {\n",
    "    'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'Model': 'ResNet18 (Custom)',\n",
    "    'Dense_Units': DENSE_UNITS,\n",
    "    'Dropout': DROPOUT_RATE,\n",
    "    'Fine_Tune_At': FINE_TUNE_AT,\n",
    "    'Optimizer': OPTIMIZER_NAME,\n",
    "    'LR_Phase_1': LR_PHASE_1,\n",
    "    'Epochs_P1': EPOCHS_PHASE_1,\n",
    "    'LR_Phase_2': LR_PHASE_2,\n",
    "    'Epochs_P2': EPOCHS_PHASE_2,\n",
    "    'Loss_Type': LOSS_TYPE,\n",
    "    'Use_Class_Weights': USE_CLASS_WEIGHTS,\n",
    "    'Test_Accuracy': round(test_accuracy, 4),\n",
    "    'Val_Acc_P1': round(best_val_acc_p1, 4),\n",
    "    'Val_Acc_P2': round(best_val_acc_p2, 4),\n",
    "    'Avg_Confidence': round(avg_conf, 4),\n",
    "    'Min_Confidence': round(min_conf, 4),\n",
    "    'Std_Confidence': round(std_conf, 4),\n",
    "    'Confusion_Matrix': cm_str,\n",
    "}\n",
    "\n",
    "# Metrik per kelas\n",
    "for label in class_labels:\n",
    "    log_data[f'{label}_Prec'] = round(report[label]['precision'], 4)\n",
    "    log_data[f'{label}_Rec'] = round(report[label]['recall'], 4)\n",
    "    log_data[f'{label}_F1'] = round(report[label]['f1-score'], 4)\n",
    "\n",
    "# Save to CSV\n",
    "df_log = pd.DataFrame([log_data])\n",
    "\n",
    "if os.path.exists(LOG_FILE_PATH):\n",
    "    df_log.to_csv(LOG_FILE_PATH, mode='a', header=False, index=False)\n",
    "    print(f\"‚úì Log ditambahkan ke: {LOG_FILE_PATH}\")\n",
    "else:\n",
    "    df_log.to_csv(LOG_FILE_PATH, index=False)\n",
    "    print(f\"‚úì File log baru dibuat: {LOG_FILE_PATH}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EKSPERIMEN SELESAI\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìÅ Model tersimpan di: {MODEL_SAVE_PATH}\")\n",
    "print(f\"üìÅ Log tersimpan di: {LOG_FILE_PATH}\")\n",
    "print(f\"\\nüéØ Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-notes",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Catatan Penting\n",
    "\n",
    "### ResNet18 Custom vs Pre-trained\n",
    "\n",
    "Model ResNet18 di notebook ini **TIDAK memiliki bobot pre-trained ImageNet**\n",
    "karena kita membangunnya dari scratch.\n",
    "\n",
    "**Solusi untuk mendapatkan pre-trained weights:**\n",
    "\n",
    "1. **PyTorch + ONNX**: Convert dari torchvision ResNet18\n",
    "2. **TensorFlow Hub**: Gunakan model dari TF Model Garden\n",
    "3. **Keras Applications**: Gunakan model yang tersedia (ResNet50, EfficientNet)\n",
    "\n",
    "### Rekomendasi\n",
    "\n",
    "Jika hasil dari ResNet18 custom tidak memuaskan:\n",
    "1. Coba **EfficientNet-B0** (5.3M params, pre-trained)\n",
    "2. Coba **MobileNetV2** (3.4M params, pre-trained)\n",
    "3. Coba **DenseNet121** (8M params, pre-trained)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
