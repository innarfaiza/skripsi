{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02855991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "# from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2b665db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path dataset dan parameter\n",
    "base_dir = pathlib.Path(\".\") \n",
    "data_split_dir = base_dir / 'dataset_final'\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "autotune = tf.data.AUTOTUNE\n",
    "\n",
    "NUM_CLASSES = 4  # Jumlah kelas untuk klasifikasi aflatoksin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98dcfd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# #path dataset dan parameter\n",
    "# base_dir = pathlib.Path(\".\") \n",
    "# data_dir = base_dir / \"data valid merah\"\n",
    "# data_split_dir =base_dir / \"data_split_merah\"\n",
    "# # data_dir = pathlib.Path(r\"D:\\SKRIPSI\\skripsi\\data valid merah\")\n",
    "# # data_split_dir = pathlib.Path(r\"D:\\SKRIPSI\\skripsi\\data_split_merah\")\n",
    "# img_height = 224\n",
    "# img_width = 224\n",
    "# batch_size = 32\n",
    "# seed = 42\n",
    "# autotune = tf.data.AUTOTUNE\n",
    "\n",
    "# # Script pembagian data: 70% train, 20% validasi, 10% test\n",
    "# print(\"Step 1: Splitting data...\")\n",
    "# def split_data_folder(source_dir, dest_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "#     source_dir = pathlib.Path(source_dir)\n",
    "#     dest_dir = pathlib.Path(dest_dir)\n",
    "#     dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     for class_folder in source_dir.iterdir():\n",
    "#         if not class_folder.is_dir():\n",
    "#             continue\n",
    "#         files = list(class_folder.glob('*.png'))\n",
    "#         if len(files) == 0:\n",
    "#             continue\n",
    "\n",
    "#         train_files, temp_files = train_test_split(files, train_size=train_ratio, random_state=42)\n",
    "#         val_size = val_ratio / (val_ratio + test_ratio)\n",
    "#         val_files, test_files = train_test_split(temp_files, train_size=val_size, random_state=42)\n",
    "\n",
    "#         for split_name, split_files in zip(['train', 'val', 'test'], [train_files, val_files, test_files]):\n",
    "#             split_class_dir = dest_dir / split_name / class_folder.name\n",
    "#             split_class_dir.mkdir(parents=True, exist_ok=True)\n",
    "#             for f in split_files:\n",
    "#                 shutil.copy(str(f), str(split_class_dir / f.name))\n",
    "\n",
    "# # Contoh penggunaan:\n",
    "# split_data_folder(\n",
    "#     source_dir=data_dir,\n",
    "#     # source_dir=r'D:\\SKRIPSI\\skripsi\\data valid merah balanced',\n",
    "#     dest_dir=data_split_dir,\n",
    "#     train_ratio=0.7, val_ratio=0.15, test_ratio=0.15\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93f06f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================PROSES PEMUATAN DATASET==================\n",
      "\n",
      "[1/3] Memuat dataset_final\\train\n",
      "Found 1400 files belonging to 4 classes.\n",
      "\n",
      "[2/3] Memuat dataset_final\\val\n",
      "Found 131 files belonging to 4 classes.\n",
      "\n",
      "[3/3] Memuat dataset_final\\test\n",
      "Found 132 files belonging to 4 classes.\n",
      "\n",
      "==================INFORMASI KELAS & MAPPING==================\n",
      "Kelas ditemukan: ['1', '2', '3', '4']\n",
      "\n",
      "Index Model     | Nama Folder     | Nilai PPB (Target)  \n",
      "------------------------------------------------------------\n",
      "0               | 1               | 1                        \n",
      "1               | 2               | 2                        \n",
      "2               | 3               | 3                        \n",
      "3               | 4               | 4                        \n",
      "\n",
      "Selesai. Dataset siap digunakan.\n"
     ]
    }
   ],
   "source": [
    "# --- HEADER UTAMA ---\n",
    "print(\"==================PROSES PEMUATAN DATASET==================\")\n",
    "# 1. Load Train Dataset\n",
    "print(f\"\\n[1/3] Memuat {data_split_dir / 'train'}\")\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_split_dir / 'train',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# 2. Load Validation Dataset\n",
    "print(f\"\\n[2/3] Memuat {data_split_dir / 'val'}\")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_split_dir / 'val',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False, \n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# 3. Load Test Dataset\n",
    "print(f\"\\n[3/3] Memuat {data_split_dir / 'test'}\")\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_split_dir / 'test',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# --- Informasi Kelas & Mapping ---\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "print(f\"\\n==================INFORMASI KELAS & MAPPING==================\")\n",
    "print(f\"Kelas ditemukan: {class_names}\")\n",
    "\n",
    "# Menampilkan Tabel Mapping yang Rapi\n",
    "print(f\"\\n{'Index Model':<15} | {'Nama Folder':<15} | {'Nilai PPB (Target)':<20}\")\n",
    "print(\"-\" * 60)\n",
    "for idx, name in enumerate(class_names):\n",
    "    print(f\"{idx:<15} | {name:<15} | {name:<25}\")\n",
    "\n",
    "print(f\"\\nSelesai. Dataset siap digunakan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a02695ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Setting up data augmentation...\n",
      "‚úì RandomFlip (horizontal)\n",
      "‚úì RandomRotation (¬±10¬∞)\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 2: Setting up data augmentation...\")\n",
    "\n",
    "# Data augmentation using Keras layers (TensorFlow 2.x compatible)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.028),  # 0.1 radians ‚âà 5.7 degrees (smaller rotation)\n",
    "    # tf.keras.layers.RandomBrightness(0.1),\n",
    "    # tf.keras.layers.RandomContrast(0.1)\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "print(\"‚úì RandomFlip (horizontal)\")\n",
    "print(\"‚úì RandomRotation (¬±10¬∞)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30edd6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: FUNGSI PREPROCESSING\n",
    "# =============================================================================\n",
    "#\n",
    "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "# ‚ïë  üîÑ PERUBAHAN: Fungsi preprocess_input yang dipanggil berbeda             ‚ïë\n",
    "# ‚ïë                                                                           ‚ïë\n",
    "# ‚ïë  Meskipun KODE-nya SAMA, PERILAKU-nya BERBEDA karena:                     ‚ïë\n",
    "# ‚ïë  - Di Cell 1, kita import dari 'efficientnet' bukan 'resnet50'            ‚ïë\n",
    "# ‚ïë  - Jadi preprocess_input() di sini adalah versi EfficientNet              ‚ïë\n",
    "# ‚ïë                                                                           ‚ïë\n",
    "# ‚ïë  PERBEDAAN NORMALISASI:                                                   ‚ïë\n",
    "# ‚ïë  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚ïë\n",
    "# ‚ïë  ‚îÇ ResNet50 (mode \"caffe\"):                                            ‚îÇ  ‚ïë\n",
    "# ‚ïë  ‚îÇ   1. Konversi RGB ‚Üí BGR                                             ‚îÇ  ‚ïë\n",
    "# ‚ïë  ‚îÇ   2. Kurangi mean ImageNet: [103.939, 116.779, 123.68]              ‚îÇ  ‚ïë\n",
    "# ‚ïë  ‚îÇ   3. Output range: sekitar [-128, 128]                              ‚îÇ  ‚ïë\n",
    "# ‚ïë  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚ïë\n",
    "# ‚ïë  ‚îÇ EfficientNet (mode \"torch\"):                                        ‚îÇ  ‚ïë\n",
    "# ‚ïë  ‚îÇ   1. Bagi dengan 255 ‚Üí range [0, 1]                                 ‚îÇ  ‚ïë\n",
    "# ‚ïë  ‚îÇ   2. Normalize: (x - mean) / std                                    ‚îÇ  ‚ïë\n",
    "# ‚ïë  ‚îÇ      mean = [0.485, 0.456, 0.406]                                   ‚îÇ  ‚ïë\n",
    "# ‚ïë  ‚îÇ      std = [0.229, 0.224, 0.225]                                    ‚îÇ  ‚ïë\n",
    "# ‚ïë  ‚îÇ   3. Output range: sekitar [-2.1, 2.6]                              ‚îÇ  ‚ïë\n",
    "# ‚ïë  ‚îÇ   4. Tetap RGB (tidak dikonversi ke BGR)                            ‚îÇ  ‚ïë\n",
    "# ‚ïë  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚ïë\n",
    "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "# =============================================================================\n",
    "\n",
    "def preprocess_for_efficientnet(images, labels, training=False):\n",
    "    \"\"\"\n",
    "    Preprocessing untuk EfficientNet.\n",
    "    \n",
    "    CATATAN: Meskipun struktur kode sama dengan versi ResNet50,\n",
    "    fungsi preprocess_input() yang dipanggil adalah versi EfficientNet\n",
    "    (karena import di Cell 1).\n",
    "    \n",
    "    Args:\n",
    "        images: Batch gambar dengan nilai pixel 0-255\n",
    "        labels: One-hot encoded labels\n",
    "        training: Boolean, True untuk training (apply augmentation)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple (preprocessed_images, labels)\n",
    "    \"\"\"\n",
    "    # Cast ke float32\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    \n",
    "    # Terapkan augmentasi HANYA saat training\n",
    "    # (hanya flip dan rotation - TIDAK ADA brightness/contrast)\n",
    "    if training:\n",
    "        images = data_augmentation(images, training=True)\n",
    "    \n",
    "    # ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è INI YANG BERBEDA PERILAKUNYA ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è\n",
    "    # Meskipun kode sama, fungsi ini adalah versi EfficientNet\n",
    "    # karena import dari tensorflow.keras.applications.efficientnet\n",
    "    images = preprocess_input(images)\n",
    "    # ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è INI YANG BERBEDA PERILAKUNYA ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83972076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menerapkan preprocessing ke dataset...\n",
      "‚úì Training dataset: augmentation ON, cache ON, prefetch ON\n",
      "‚úì Validation dataset: augmentation OFF, cache ON, prefetch ON\n",
      "‚úì Test dataset: augmentation OFF, cache ON, prefetch ON\n",
      "\n",
      "============================================================\n",
      "PREPROCESSING SELESAI\n",
      "============================================================\n",
      "\n",
      "Dataset siap digunakan untuk training EfficientNet-B0!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: TERAPKAN PREPROCESSING & OPTIMASI PIPELINE\n",
    "# =============================================================================\n",
    "#\n",
    "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "# ‚ïë  üîÑ PERUBAHAN: Menambahkan .cache() dan .prefetch()                       ‚ïë\n",
    "# ‚ïë                                                                           ‚ïë\n",
    "# ‚ïë  SEBELUM (ResNet50):                                                      ‚ïë\n",
    "# ‚ïë  train_ds = train_ds.map(...)                                             ‚ïë\n",
    "# ‚ïë                                                                           ‚ïë\n",
    "# ‚ïë  SESUDAH (EfficientNet):                                                  ‚ïë\n",
    "# ‚ïë  train_ds = train_ds.map(...).cache().prefetch(...)                       ‚ïë\n",
    "# ‚ïë                                                                           ‚ïë\n",
    "# ‚ïë  PENJELASAN:                                                              ‚ïë\n",
    "# ‚ïë  ‚Ä¢ .cache() = simpan data di memory setelah load pertama                  ‚ïë\n",
    "# ‚ïë               Epoch 2+ akan lebih cepat karena tidak perlu baca disk      ‚ïë\n",
    "# ‚ïë  ‚Ä¢ .prefetch() = load batch berikutnya sementara GPU proses batch saat ini‚ïë\n",
    "# ‚ïë                  Menghilangkan bottleneck I/O                             ‚ïë\n",
    "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Menerapkan preprocessing ke dataset...\")\n",
    "\n",
    "# Training Dataset\n",
    "# ‚¨áÔ∏è PERUBAHAN: Menambahkan .cache().prefetch() ‚¨áÔ∏è\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: preprocess_for_efficientnet(x, y, training=True),\n",
    "    num_parallel_calls=autotune\n",
    ").cache().prefetch(buffer_size=autotune)\n",
    "\n",
    "print(\"‚úì Training dataset: augmentation ON, cache ON, prefetch ON\")\n",
    "\n",
    "# Validation Dataset\n",
    "# ‚¨áÔ∏è PERUBAHAN: Menambahkan .cache().prefetch() ‚¨áÔ∏è\n",
    "val_ds = val_ds.map(\n",
    "    lambda x, y: preprocess_for_efficientnet(x, y, training=False),\n",
    "    num_parallel_calls=autotune\n",
    ").cache().prefetch(buffer_size=autotune)\n",
    "\n",
    "print(\"‚úì Validation dataset: augmentation OFF, cache ON, prefetch ON\")\n",
    "\n",
    "# Test Dataset\n",
    "# ‚¨áÔ∏è PERUBAHAN: Menambahkan .cache().prefetch() ‚¨áÔ∏è\n",
    "test_ds = test_ds.map(\n",
    "    lambda x, y: preprocess_for_efficientnet(x, y, training=False),\n",
    "    num_parallel_calls=autotune\n",
    ").cache().prefetch(buffer_size=autotune)\n",
    "\n",
    "print(\"‚úì Test dataset: augmentation OFF, cache ON, prefetch ON\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPROCESSING SELESAI\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDataset siap digunakan untuk training EfficientNet-B0!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ef9f1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifikasi preprocessing...\n",
      "\n",
      "Batch shape: (32, 224, 224, 3)\n",
      "Labels shape: (32, 4)\n",
      "\n",
      "Statistik pixel setelah preprocessing:\n",
      "  - Min: 0.0000\n",
      "  - Max: 209.3575\n",
      "  - Mean: 0.1618\n",
      "  - Std: 2.7151\n",
      "\n",
      "‚ö†Ô∏è WARNING: Range nilai terlihat seperti ResNet50!\n",
      "   Pastikan import dari efficientnet, bukan resnet50\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: VERIFIKASI PREPROCESSING\n",
    "# =============================================================================\n",
    "# Cell ini memverifikasi bahwa preprocessing EfficientNet bekerja dengan benar\n",
    "# Range nilai yang diharapkan: sekitar [-2.1, 2.6] (berbeda dengan ResNet50!)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Verifikasi preprocessing...\")\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(f\"\\nBatch shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"\\nStatistik pixel setelah preprocessing:\")\n",
    "    print(f\"  - Min: {tf.reduce_min(images).numpy():.4f}\")\n",
    "    print(f\"  - Max: {tf.reduce_max(images).numpy():.4f}\")\n",
    "    print(f\"  - Mean: {tf.reduce_mean(images).numpy():.4f}\")\n",
    "    print(f\"  - Std: {tf.math.reduce_std(images).numpy():.4f}\")\n",
    "    \n",
    "    min_val = tf.reduce_min(images).numpy()\n",
    "    max_val = tf.reduce_max(images).numpy()\n",
    "    \n",
    "    # EfficientNet preprocess_input menghasilkan nilai dalam range sekitar [-2.1, 2.6]\n",
    "    # (berbeda dengan ResNet50 yang ~[-128, 128])\n",
    "    if -3 < min_val < 0 and 0 < max_val < 3:\n",
    "        print(\"\\n‚úÖ Range nilai sesuai dengan ekspektasi EfficientNet\")\n",
    "        print(\"   (EfficientNet: ~[-2.1, 2.6], ResNet50: ~[-128, 128])\")\n",
    "    elif min_val < -50 or max_val > 50:\n",
    "        print(\"\\n‚ö†Ô∏è WARNING: Range nilai terlihat seperti ResNet50!\")\n",
    "        print(\"   Pastikan import dari efficientnet, bukan resnet50\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Range nilai tidak sesuai ekspektasi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
