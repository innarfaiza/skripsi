{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f03c95",
   "metadata": {},
   "source": [
    "## ğŸ“š PENJELASAN KONFIGURASI - RESNET18 + CBAM\n",
    "\n",
    "### âš ï¸ CATATAN PENTING\n",
    "**ResNet18 TIDAK tersedia di `tensorflow.keras.applications`!**\n",
    "\n",
    "Notebook ini menggunakan **Custom ResNet18 + CBAM (Convolutional Block Attention Module)** yang dibangun manual.\n",
    "\n",
    "### ğŸ§  Apa Itu CBAM?\n",
    "CBAM adalah **attention mechanism** yang membantu model \"fokus\" pada fitur yang paling penting.\n",
    "CBAM terdiri dari 2 komponen:\n",
    "\n",
    "1. **Channel Attention** â†’ Menentukan **\"APA\"** yang penting (channel/filter mana yang relevan)\n",
    "   - Menggunakan Global Average Pooling + Global Max Pooling\n",
    "   - Shared MLP untuk menghasilkan bobot per channel\n",
    "   \n",
    "2. **Spatial Attention** â†’ Menentukan **\"DI MANA\"** yang penting (lokasi mana di gambar)\n",
    "   - Menggunakan Average + Max pooling across channels\n",
    "   - Conv 7Ã—7 untuk menghasilkan attention map spasial\n",
    "\n",
    "### ğŸ“Š Referensi\n",
    "- **Woo et al. (2018)** \"CBAM: Convolutional Block Attention Module\" - ECCV 2018\n",
    "- ResNet50 + CBAM: Top-1 Error 22.66% vs 24.56% baseline (ImageNet)\n",
    "\n",
    "### ğŸŒ½ Mengapa CBAM untuk Aflatoxin?\n",
    "- **Spatial attention** membantu fokus pada area kernel jagung yang berfluoresensi\n",
    "- **Channel attention** memilih spektral/warna yang relevan untuk deteksi aflatoxin\n",
    "\n",
    "### âš™ï¸ Parameter Baru\n",
    "| Parameter | Default | Penjelasan |\n",
    "|-----------|---------|------------|\n",
    "| `USE_CBAM` | True | Aktifkan/nonaktifkan CBAM |\n",
    "| `SE_REDUCTION_RATIO` | 16 | Rasio reduksi bottleneck di channel attention |\n",
    "| `SPATIAL_KERNEL_SIZE` | 7 | Ukuran kernel untuk spatial attention (7 optimal) |\n",
    "\n",
    "### ğŸ“ Perbedaan dengan ModelResNet18.ipynb (Tanpa CBAM)\n",
    "| Aspek | Tanpa CBAM | Dengan CBAM |\n",
    "|-------|------------|-------------|\n",
    "| Basic Block | Convâ†’BNâ†’ReLUâ†’Convâ†’BNâ†’Add | Convâ†’BNâ†’ReLUâ†’Convâ†’BNâ†’**CBAM**â†’Add |\n",
    "| Parameter | ~11.2M | ~11.3M (+0.1M dari CBAM) |\n",
    "| Fokus Model | Semua fitur sama rata | Fitur penting diberi bobot lebih |\n",
    "| Interpretability | Grad-CAM saja | Grad-CAM + Attention Map |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "327f05f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "TensorFlow Hub version: 0.16.1\n",
      "GPU Available: []\n",
      "Konfigurasi:\n",
      "  - Image Size: 224x224\n",
      "  - Batch Size: 32\n",
      "  - Num Classes: 4\n",
      "  - Data Path: dataset_final\n",
      "============================================================\n",
      "PROSES PEMUATAN DATASET\n",
      "============================================================\n",
      "\n",
      "[1/3] Memuat dataset_final\\train\n",
      "Found 1200 files belonging to 4 classes.\n",
      "\n",
      "[2/3] Memuat dataset_final\\val\n",
      "Found 131 files belonging to 4 classes.\n",
      "\n",
      "[3/3] Memuat dataset_final\\test\n",
      "Found 132 files belonging to 4 classes.\n",
      "\n",
      "============================================================\n",
      "INFORMASI KELAS & MAPPING\n",
      "============================================================\n",
      "Kelas ditemukan: ['1', '2', '3', '4']\n",
      "\n",
      "Index      | Folder     | Kandungan Aflatoksin\n",
      "--------------------------------------------------\n",
      "0          | 1          | 1 PPB\n",
      "1          | 2          | 2 PPB\n",
      "2          | 3          | 3 PPB\n",
      "3          | 4          | 4 PPB\n",
      "Setting up data augmentation...\n",
      "âœ“ RandomFlip (horizontal)\n",
      "âœ“ RandomRotation (Â±1.6Â°)\n",
      "\n",
      "âŒ RandomBrightness - TIDAK DIGUNAKAN (mengubah nilai PPB)\n",
      "âŒ RandomContrast - TIDAK DIGUNAKAN (mengubah nilai PPB)\n",
      "Fungsi preprocessing untuk ResNet18 telah dibuat.\n",
      "\n",
      "Normalisasi yang digunakan:\n",
      "  - Input: [0, 255]\n",
      "  - Output: [0, 1]\n",
      "Menerapkan preprocessing ke dataset...\n",
      "âœ“ Training dataset: augmentation ON, cache ON, prefetch ON\n",
      "âœ“ Validation dataset: augmentation OFF, cache ON, prefetch ON\n",
      "âœ“ Test dataset: augmentation OFF, cache ON, prefetch ON\n",
      "\n",
      "============================================================\n",
      "PREPROCESSING SELESAI\n",
      "============================================================\n",
      "\n",
      "Dataset siap digunakan untuk training ResNet18!\n",
      "Verifikasi preprocessing...\n",
      "\n",
      "Batch shape: (32, 224, 224, 3)\n",
      "Labels shape: (32,)\n",
      "\n",
      "Statistik pixel setelah preprocessing:\n",
      "  - Min: 0.0000\n",
      "  - Max: 0.7971\n",
      "  - Mean: 0.0005\n",
      "  - Std: 0.0103\n",
      "\n",
      "âœ… Range nilai sesuai dengan ekspektasi ResNet18 [0, 1]\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 1. SETUP & LOAD DATA (MENGGUNAKAN PREPROCESS YANG SUDAH ADA)\n",
    "# =================================================================================================\n",
    "\n",
    "# Memanggil file preprocess_resnet18.ipynb agar variabel train_ds, val_ds, test_ds tersedia\n",
    "# Pastikan file preprocess_resnet18.ipynb berada di folder yang sama\n",
    "%run preprocess_resnet18.ipynb\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, GlobalAveragePooling2D, GlobalMaxPooling2D, Dropout, Input,\n",
    "    Conv2D, BatchNormalization, Activation, MaxPooling2D, Add,\n",
    "    Reshape, Multiply, Concatenate, Lambda\n",
    ")\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import AdamW, SGD, RMSprop, Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class FocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=1.0, gamma=2.0, name='focal_loss'):\n",
    "        super().__init__(name=name)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # Clip predictions\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        # Calculate cross entropy\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        \n",
    "        # Calculate focal weight\n",
    "        pt = y_true * y_pred\n",
    "        pt = tf.reduce_sum(pt, axis=-1, keepdims=True)\n",
    "        focal_weight = tf.pow(1.0 - pt, self.gamma)\n",
    "        \n",
    "        # Apply focal loss\n",
    "        focal_loss = self.alpha * focal_weight * tf.reduce_sum(ce, axis=-1, keepdims=True)\n",
    "        \n",
    "        return tf.reduce_mean(focal_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be9e6987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CUSTOM RESNET18 + CBAM ARCHITECTURE\n",
      "============================================================\n",
      "\n",
      "Struktur ResNet18 + CBAM:\n",
      "  - Conv1: 7x7, 64 filters, stride 2\n",
      "  - MaxPool: 3x3, stride 2\n",
      "  - Layer1: 2 basic blocks Ã— 64 filters  + CBAM\n",
      "  - Layer2: 2 basic blocks Ã— 128 filters + CBAM\n",
      "  - Layer3: 2 basic blocks Ã— 256 filters + CBAM\n",
      "  - Layer4: 2 basic blocks Ã— 512 filters + CBAM\n",
      "  - Global Average Pooling â†’ 512-dim\n",
      "\n",
      "âœ“ With CBAM    - Layers: 169, Params: 11,275,976\n",
      "âœ“ Without CBAM - Layers: 65, Params: 11,186,112\n",
      "âœ“ CBAM overhead: +89,864 parameters\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 1.5 CBAM MODULE + CUSTOM RESNET18 BUILDER\n",
    "# =================================================================================================\n",
    "# CBAM = Convolutional Block Attention Module (Woo et al., ECCV 2018)\n",
    "# Terdiri dari: Channel Attention â†’ Spatial Attention (sequential)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CBAM COMPONENTS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def channel_attention(input_tensor, reduction_ratio=16, name='ca'):\n",
    "    \"\"\"\n",
    "    Channel Attention Module\n",
    "    \n",
    "    Menentukan \"APA\" yang penting â†’ bobot per channel\n",
    "    \n",
    "    Flow: Input â†’ [AvgPool + MaxPool] â†’ SharedMLP â†’ Sigmoid â†’ Scale\n",
    "    \n",
    "    Args:\n",
    "        input_tensor: Feature map [batch, H, W, C]\n",
    "        reduction_ratio: Bottleneck ratio (default: 16)\n",
    "    Returns:\n",
    "        Recalibrated feature map [batch, H, W, C]\n",
    "    \"\"\"\n",
    "    channels = input_tensor.shape[-1]\n",
    "    \n",
    "    # Shared MLP layers (digunakan untuk avg dan max path)\n",
    "    shared_dense1 = Dense(channels // reduction_ratio, activation='relu', name=f'{name}_fc1')\n",
    "    shared_dense2 = Dense(channels, activation=None, name=f'{name}_fc2')\n",
    "    \n",
    "    # === Average Pooling Path ===\n",
    "    avg_pool = GlobalAveragePooling2D(name=f'{name}_avgpool')(input_tensor)\n",
    "    avg_out = shared_dense1(avg_pool)\n",
    "    avg_out = shared_dense2(avg_out)\n",
    "    \n",
    "    # === Max Pooling Path ===\n",
    "    max_pool = GlobalMaxPooling2D(name=f'{name}_maxpool')(input_tensor)\n",
    "    max_out = shared_dense1(max_pool)\n",
    "    max_out = shared_dense2(max_out)\n",
    "    \n",
    "    # === Combine + Sigmoid ===\n",
    "    attention = Add(name=f'{name}_add')([avg_out, max_out])\n",
    "    attention = Activation('sigmoid', name=f'{name}_sigmoid')(attention)\n",
    "    attention = Reshape((1, 1, channels), name=f'{name}_reshape')(attention)\n",
    "    \n",
    "    # === Scale (element-wise multiply) ===\n",
    "    output = Multiply(name=f'{name}_scale')([input_tensor, attention])\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def spatial_attention(input_tensor, kernel_size=7, name='sa'):\n",
    "    \"\"\"\n",
    "    Spatial Attention Module\n",
    "    \n",
    "    Menentukan \"DI MANA\" yang penting â†’ bobot per lokasi pixel\n",
    "    \n",
    "    Flow: Input â†’ [AvgPool + MaxPool across C] â†’ Concat â†’ Conv7x7 â†’ Sigmoid â†’ Scale\n",
    "    \n",
    "    Args:\n",
    "        input_tensor: Feature map [batch, H, W, C]\n",
    "        kernel_size: Convolution kernel size (default: 7)\n",
    "    Returns:\n",
    "        Recalibrated feature map [batch, H, W, C]\n",
    "    \"\"\"\n",
    "    # Average pooling across channel axis â†’ [batch, H, W, 1]\n",
    "    avg_pool = Lambda(\n",
    "        lambda x: tf.reduce_mean(x, axis=-1, keepdims=True),\n",
    "        name=f'{name}_avgpool'\n",
    "    )(input_tensor)\n",
    "    \n",
    "    # Max pooling across channel axis â†’ [batch, H, W, 1]\n",
    "    max_pool = Lambda(\n",
    "        lambda x: tf.reduce_max(x, axis=-1, keepdims=True),\n",
    "        name=f'{name}_maxpool'\n",
    "    )(input_tensor)\n",
    "    \n",
    "    # Concatenate â†’ [batch, H, W, 2]\n",
    "    concat = Concatenate(axis=-1, name=f'{name}_concat')([avg_pool, max_pool])\n",
    "    \n",
    "    # Convolution â†’ [batch, H, W, 1]\n",
    "    attention = Conv2D(\n",
    "        1, kernel_size, padding='same', \n",
    "        activation='sigmoid', use_bias=False,\n",
    "        name=f'{name}_conv'\n",
    "    )(concat)\n",
    "    \n",
    "    # Scale (element-wise multiply)\n",
    "    output = Multiply(name=f'{name}_scale')([input_tensor, attention])\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def cbam_block(input_tensor, reduction_ratio=16, kernel_size=7, name='cbam'):\n",
    "    \"\"\"\n",
    "    CBAM: Sequential Channel â†’ Spatial Attention\n",
    "    \n",
    "    Paper: Woo et al. \"CBAM\" ECCV 2018\n",
    "    Sequential order (Channel â†’ Spatial) terbukti lebih baik dari parallel.\n",
    "    \n",
    "    Args:\n",
    "        input_tensor: Feature map [batch, H, W, C]\n",
    "        reduction_ratio: Channel attention bottleneck ratio\n",
    "        kernel_size: Spatial attention conv kernel size\n",
    "    Returns:\n",
    "        Refined feature map [batch, H, W, C]\n",
    "    \"\"\"\n",
    "    # Step 1: Channel Attention (\"APA\" yang penting)\n",
    "    x = channel_attention(input_tensor, reduction_ratio, name=f'{name}_ch')\n",
    "    \n",
    "    # Step 2: Spatial Attention (\"DI MANA\" yang penting)\n",
    "    x = spatial_attention(x, kernel_size, name=f'{name}_sp')\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# RESNET18 BUILDING BLOCKS (DENGAN CBAM)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def basic_block(x, filters, stride=1, downsample=None, \n",
    "                use_cbam=True, reduction_ratio=16, spatial_kernel=7, name=None):\n",
    "    \"\"\"\n",
    "    Basic Block untuk ResNet18/34 + Optional CBAM\n",
    "    \n",
    "    Struktur:\n",
    "    - Tanpa CBAM: x â†’ Conv3x3 â†’ BN â†’ ReLU â†’ Conv3x3 â†’ BN â†’ Add(x) â†’ ReLU\n",
    "    - Dengan CBAM: x â†’ Conv3x3 â†’ BN â†’ ReLU â†’ Conv3x3 â†’ BN â†’ CBAM â†’ Add(x) â†’ ReLU\n",
    "    \"\"\"\n",
    "    identity = x\n",
    "    \n",
    "    # First conv\n",
    "    out = Conv2D(filters, 3, strides=stride, padding='same', \n",
    "                 use_bias=False, name=f'{name}_conv1')(x)\n",
    "    out = BatchNormalization(name=f'{name}_bn1')(out)\n",
    "    out = Activation('relu', name=f'{name}_relu1')(out)\n",
    "    \n",
    "    # Second conv\n",
    "    out = Conv2D(filters, 3, strides=1, padding='same', \n",
    "                 use_bias=False, name=f'{name}_conv2')(out)\n",
    "    out = BatchNormalization(name=f'{name}_bn2')(out)\n",
    "    \n",
    "    # â˜…â˜…â˜… CBAM ATTENTION â˜…â˜…â˜…\n",
    "    if use_cbam:\n",
    "        out = cbam_block(out, reduction_ratio, spatial_kernel, name=f'{name}_cbam')\n",
    "    \n",
    "    # Shortcut connection\n",
    "    if downsample is not None:\n",
    "        identity = downsample(x)\n",
    "    \n",
    "    out = Add(name=f'{name}_add')([out, identity])\n",
    "    out = Activation('relu', name=f'{name}_relu2')(out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def make_layer(x, filters, blocks, stride=1, \n",
    "               use_cbam=True, reduction_ratio=16, spatial_kernel=7, name=None):\n",
    "    \"\"\"\n",
    "    Membuat layer yang terdiri dari beberapa basic blocks\n",
    "    \"\"\"\n",
    "    downsample = None\n",
    "    \n",
    "    # Jika stride != 1 atau jumlah filter berubah, perlu downsample\n",
    "    if stride != 1 or x.shape[-1] != filters:\n",
    "        downsample = Sequential([\n",
    "            Conv2D(filters, 1, strides=stride, use_bias=False),\n",
    "            BatchNormalization()\n",
    "        ], name=f'{name}_downsample')\n",
    "    \n",
    "    # First block (mungkin perlu downsample)\n",
    "    x = basic_block(x, filters, stride, downsample, \n",
    "                    use_cbam, reduction_ratio, spatial_kernel,\n",
    "                    name=f'{name}_block1')\n",
    "    \n",
    "    # Remaining blocks\n",
    "    for i in range(1, blocks):\n",
    "        x = basic_block(x, filters, \n",
    "                       use_cbam=use_cbam, \n",
    "                       reduction_ratio=reduction_ratio,\n",
    "                       spatial_kernel=spatial_kernel,\n",
    "                       name=f'{name}_block{i+1}')\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_resnet18_base(input_shape=(224, 224, 3), \n",
    "                        use_cbam=True, reduction_ratio=16, spatial_kernel=7):\n",
    "    \"\"\"\n",
    "    Membangun base ResNet18 + CBAM (tanpa classification head)\n",
    "    \n",
    "    Struktur:\n",
    "    - Conv1: 7x7, 64 filters, stride 2\n",
    "    - MaxPool: 3x3, stride 2  \n",
    "    - Layer1: 2 basic blocks, 64 filters  (+CBAM)\n",
    "    - Layer2: 2 basic blocks, 128 filters (+CBAM)\n",
    "    - Layer3: 2 basic blocks, 256 filters (+CBAM)\n",
    "    - Layer4: 2 basic blocks, 512 filters (+CBAM)\n",
    "    - Global Average Pooling â†’ Output: 512-dim vector\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "    \n",
    "    # Initial convolution (conv1)\n",
    "    x = Conv2D(64, 7, strides=2, padding='same', use_bias=False, name='conv1')(inputs)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = Activation('relu', name='relu1')(x)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same', name='maxpool')(x)\n",
    "    \n",
    "    # Residual layers (CBAM diterapkan di setiap basic block)\n",
    "    x = make_layer(x, 64,  2, stride=1, use_cbam=use_cbam, \n",
    "                   reduction_ratio=reduction_ratio, spatial_kernel=spatial_kernel, name='layer1')\n",
    "    x = make_layer(x, 128, 2, stride=2, use_cbam=use_cbam,\n",
    "                   reduction_ratio=reduction_ratio, spatial_kernel=spatial_kernel, name='layer2')\n",
    "    x = make_layer(x, 256, 2, stride=2, use_cbam=use_cbam,\n",
    "                   reduction_ratio=reduction_ratio, spatial_kernel=spatial_kernel, name='layer3')\n",
    "    x = make_layer(x, 512, 2, stride=2, use_cbam=use_cbam,\n",
    "                   reduction_ratio=reduction_ratio, spatial_kernel=spatial_kernel, name='layer4')\n",
    "    \n",
    "    # Global average pooling\n",
    "    x = GlobalAveragePooling2D(name='avgpool')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x, name='resnet18_cbam_base')\n",
    "    return model\n",
    "\n",
    "# Test build dan tampilkan info\n",
    "print(\"=\" * 60)\n",
    "print(\"CUSTOM RESNET18 + CBAM ARCHITECTURE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nStruktur ResNet18 + CBAM:\")\n",
    "print(\"  - Conv1: 7x7, 64 filters, stride 2\")\n",
    "print(\"  - MaxPool: 3x3, stride 2\")\n",
    "print(\"  - Layer1: 2 basic blocks Ã— 64 filters  + CBAM\")\n",
    "print(\"  - Layer2: 2 basic blocks Ã— 128 filters + CBAM\")\n",
    "print(\"  - Layer3: 2 basic blocks Ã— 256 filters + CBAM\")\n",
    "print(\"  - Layer4: 2 basic blocks Ã— 512 filters + CBAM\")\n",
    "print(\"  - Global Average Pooling â†’ 512-dim\")\n",
    "\n",
    "_test_base = build_resnet18_base(use_cbam=True)\n",
    "_test_base_no_cbam = build_resnet18_base(use_cbam=False)\n",
    "print(f\"\\nâœ“ With CBAM    - Layers: {len(_test_base.layers)}, Params: {_test_base.count_params():,}\")\n",
    "print(f\"âœ“ Without CBAM - Layers: {len(_test_base_no_cbam.layers)}, Params: {_test_base_no_cbam.count_params():,}\")\n",
    "print(f\"âœ“ CBAM overhead: +{_test_base.count_params() - _test_base_no_cbam.count_params():,} parameters\")\n",
    "del _test_base, _test_base_no_cbam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed809ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KONFIGURASI EKSPERIMEN RESNET18 + CBAM\n",
      "============================================================\n",
      "\n",
      "ğŸ§  CBAM Attention:\n",
      "   Use CBAM: True\n",
      "   Reduction Ratio: 16\n",
      "   Spatial Kernel: 7\n",
      "\n",
      "ğŸ“ Arsitektur:\n",
      "   Layer Config: [256, 128]\n",
      "   Dropout: 0.5\n",
      "   Fine-tune at: 40\n",
      "\n",
      "ğŸ“ˆ Phase 1:\n",
      "   LR: 0.001, Epochs: 40\n",
      "\n",
      "ğŸ“ˆ Phase 2:\n",
      "   LR: 0.0001, Epochs: 30\n",
      "\n",
      "âš–ï¸ Class Weights: True\n",
      "   {0: 1.18, 1: 0.83, 2: 1.05, 3: 1.67}\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 2. KONFIGURASI EKSPERIMEN (UBAH PARAMETER DI SINI SETIAP KALI RUNNING)\n",
    "# =================================================================================================\n",
    "# Ini adalah \"Control Panel\" kamu. Ubah angka di sini, lalu Run All.\n",
    "\n",
    "# --- Parameter CBAM (BARU!) ---\n",
    "USE_CBAM = True             # True = pakai CBAM, False = ResNet18 biasa\n",
    "SE_REDUCTION_RATIO = 16     # Rasio bottleneck channel attention (default: 16)\n",
    "SPATIAL_KERNEL_SIZE = 7     # Kernel size spatial attention (7 optimal, bisa coba 3)\n",
    "\n",
    "# --- Parameter Arsitektur Model ---\n",
    "LAYER_CONFIG = [256, 128]   # Konfigurasi layer Dense bertingkat\n",
    "                            # Lebih sederhana dari ResNet50 karena model lebih kecil\n",
    "DROPOUT_RATE = 0.5          # 0.5 artinya 50% neuron dimatikan acak saat training\n",
    "FINE_TUNE_AT = 40           # Layer ResNet18 (total ~60) mulai dari mana kita 'cairkan'\n",
    "                            # ResNet18 lebih kecil, jadi fine-tune dari layer lebih awal\n",
    "\n",
    "# --- Parameter Training Phase 1 (Feature Extraction - Base Model Beku) ---\n",
    "LR_PHASE_1 = 1e-3           # Learning Rate lebih tinggi karena training from scratch\n",
    "EPOCHS_PHASE_1 = 40         # Epoch lebih banyak karena tanpa pre-trained weights\n",
    "\n",
    "# --- Parameter Training Phase 2 (Fine Tuning - Base Model Cair Sebagian) ---\n",
    "LR_PHASE_2 = 1e-4           # LR untuk fine-tuning\n",
    "EPOCHS_PHASE_2 = 30         # Epoch lanjutan\n",
    "\n",
    "# --- Lainnya ---\n",
    "BATCH_SIZE = 32             # Jumlah gambar yang diproses sekali jalan\n",
    "OPTIMIZER_NAME = 'Adam'     # Pilihan: 'Adam', 'AdamW', 'SGD', 'RMSprop'\n",
    "LOG_FILE_PATH = 'experiment_log_resnet18_cbam.csv'  # Nama file untuk menyimpan hasil\n",
    "MODEL_SAVE_PATH = 'best_resnet18_cbam_aflatoxin.keras'\n",
    "\n",
    "# --- Regularisasi ---\n",
    "LABEL_SMOOTHING = 0         # Label smoothing (0 = off)\n",
    "\n",
    "# --- Class Weights Moderat (Sqrt Balanced berdasarkan foto UNIK) ---\n",
    "USE_CLASS_WEIGHTS = True    # Set False jika ingin menonaktifkan\n",
    "CLASS_WEIGHTS = {\n",
    "    0: 1.18,    # Kelas 1 (128 foto unik)\n",
    "    1: 0.83,    # Kelas 2 (256 foto unik)\n",
    "    2: 1.05,    # Kelas 3 (161 foto unik)\n",
    "    3: 1.67,    # Kelas 4 (63 foto unik)\n",
    "}\n",
    "\n",
    "# --- Print Konfigurasi ---\n",
    "print(\"=\" * 60)\n",
    "print(\"KONFIGURASI EKSPERIMEN RESNET18 + CBAM\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nğŸ§  CBAM Attention:\")\n",
    "print(f\"   Use CBAM: {USE_CBAM}\")\n",
    "if USE_CBAM:\n",
    "    print(f\"   Reduction Ratio: {SE_REDUCTION_RATIO}\")\n",
    "    print(f\"   Spatial Kernel: {SPATIAL_KERNEL_SIZE}\")\n",
    "print(f\"\\nğŸ“ Arsitektur:\")\n",
    "print(f\"   Layer Config: {LAYER_CONFIG}\")\n",
    "print(f\"   Dropout: {DROPOUT_RATE}\")\n",
    "print(f\"   Fine-tune at: {FINE_TUNE_AT}\")\n",
    "print(f\"\\nğŸ“ˆ Phase 1:\")\n",
    "print(f\"   LR: {LR_PHASE_1}, Epochs: {EPOCHS_PHASE_1}\")\n",
    "print(f\"\\nğŸ“ˆ Phase 2:\")\n",
    "print(f\"   LR: {LR_PHASE_2}, Epochs: {EPOCHS_PHASE_2}\")\n",
    "print(f\"\\nâš–ï¸ Class Weights: {USE_CLASS_WEIGHTS}\")\n",
    "if USE_CLASS_WEIGHTS:\n",
    "    print(f\"   {CLASS_WEIGHTS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dab4ce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Model dibangun WITH CBAM\n",
      "âœ“ Optimizer: Adam | LR Awal: 0.001\n",
      "âœ“ Loss: Focal Loss (alpha=1.0, gamma=2.0)\n",
      "âœ“ Metrics: accuracy\n",
      "Model compiled successfully!\n",
      "\n",
      "Total parameters: 11,440,716\n",
      "Base model layers: 169\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 3. MEMBANGUN MODEL (ARSITEKTUR RESNET18 + CBAM)\n",
    "# =================================================================================================\n",
    "\n",
    "def build_model_experiment():\n",
    "    # Menggunakan Custom ResNet18 + CBAM sebagai base\n",
    "    # CATATAN: Tidak ada pre-trained weights!\n",
    "    base_model = build_resnet18_base(\n",
    "        input_shape=(224, 224, 3),\n",
    "        use_cbam=USE_CBAM,\n",
    "        reduction_ratio=SE_REDUCTION_RATIO,\n",
    "        spatial_kernel=SPATIAL_KERNEL_SIZE\n",
    "    )\n",
    "    \n",
    "    # Freeze Base Model: Kita kunci bobot ResNet agar tidak berubah di Fase 1\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    for units in LAYER_CONFIG:\n",
    "        # Tambah Dense Layer\n",
    "        x = Dense(units, activation='relu')(x)\n",
    "        if DROPOUT_RATE > 0:\n",
    "            x = Dropout(DROPOUT_RATE)(x)\n",
    "    \n",
    "    # Output Layer (4 Kelas)\n",
    "    output = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    return model, base_model\n",
    "\n",
    "# Inisialisasi Model\n",
    "model, base_model = build_model_experiment()\n",
    "\n",
    "# Setup Optimizer Dinamis sesuai Konfigurasi\n",
    "if OPTIMIZER_NAME.lower() == 'adam':\n",
    "    opt = Adam(learning_rate=LR_PHASE_1)\n",
    "elif OPTIMIZER_NAME.lower() == 'sgd':\n",
    "    opt = SGD(learning_rate=LR_PHASE_1, momentum=0.9)\n",
    "elif OPTIMIZER_NAME.lower() == 'adamw':\n",
    "    opt = AdamW(learning_rate=LR_PHASE_1)\n",
    "else:\n",
    "    opt = RMSprop(learning_rate=LR_PHASE_1)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt, \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cbam_status = \"WITH CBAM\" if USE_CBAM else \"WITHOUT CBAM\"\n",
    "print(f\"\\n[INFO] Model dibangun {cbam_status}\")\n",
    "print(f\"âœ“ Optimizer: {OPTIMIZER_NAME} | LR Awal: {LR_PHASE_1}\")\n",
    "print(f\"âœ“ Loss: Focal Loss (alpha=1.0, gamma=2.0)\")\n",
    "print(f\"âœ“ Metrics: accuracy\")\n",
    "print(f\"Model compiled successfully!\")\n",
    "print(f\"\\nTotal parameters: {model.count_params():,}\")\n",
    "print(f\"Base model layers: {len(base_model.layers)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19f9fce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up training callbacks...\n",
      "âœ“ EarlyStopping (monitor='val_accuracy', patience=15)\n",
      "âœ“ ReduceLROnPlateau (factor=0.5, patience=8)\n",
      "âœ“ ModelCheckpoint (save to: best_resnet18_cbam_aflatoxin.keras)\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up training callbacks...\")\n",
    "\n",
    "# Training callbacks for better training control\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=15,        # Lebih sabar karena training from scratch\n",
    "        mode='max',\n",
    "        restore_best_weights=True, \n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=8,\n",
    "        min_lr=1e-8,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        MODEL_SAVE_PATH,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"âœ“ EarlyStopping (monitor='val_accuracy', patience=15)\")\n",
    "print(\"âœ“ ReduceLROnPlateau (factor=0.5, patience=8)\")\n",
    "print(f\"âœ“ ModelCheckpoint (save to: {MODEL_SAVE_PATH})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab3c80dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] === PHASE 1: Training Head Only (40 Epochs) ===\n",
      "âœ“ Class Weights aktif: {0: 1.18, 1: 0.83, 2: 1.05, 3: 1.67}\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2369 - loss: 1.6124\n",
      "Epoch 1: val_accuracy improved from None to 0.10687, saving model to best_resnet18_cbam_aflatoxin.keras\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step - accuracy: 0.2508 - loss: 1.6238 - val_accuracy: 0.1069 - val_loss: 1.4614 - learning_rate: 0.0010\n",
      "Epoch 2/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.5966\n",
      "Epoch 2: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.2500 - loss: 1.6041 - val_accuracy: 0.1069 - val_loss: 1.5373 - learning_rate: 0.0010\n",
      "Epoch 3/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.5963\n",
      "Epoch 3: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.2500 - loss: 1.6030 - val_accuracy: 0.1069 - val_loss: 1.5398 - learning_rate: 0.0010\n",
      "Epoch 4/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.5984\n",
      "Epoch 4: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 1.6068 - val_accuracy: 0.1069 - val_loss: 1.5325 - learning_rate: 0.0010\n",
      "Epoch 5/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.5965\n",
      "Epoch 5: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 1.6029 - val_accuracy: 0.1069 - val_loss: 1.5397 - learning_rate: 0.0010\n",
      "Epoch 6/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.5984\n",
      "Epoch 6: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 1.6013 - val_accuracy: 0.1069 - val_loss: 1.5424 - learning_rate: 0.0010\n",
      "Epoch 7/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.5942\n",
      "Epoch 7: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 1.5992 - val_accuracy: 0.1069 - val_loss: 1.5448 - learning_rate: 0.0010\n",
      "Epoch 8/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.5977\n",
      "Epoch 8: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.2500 - loss: 1.6031 - val_accuracy: 0.1069 - val_loss: 1.5329 - learning_rate: 0.0010\n",
      "Epoch 9/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.5984\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 1.6044 - val_accuracy: 0.1069 - val_loss: 1.5329 - learning_rate: 0.0010\n",
      "Epoch 10/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.6007\n",
      "Epoch 10: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 1.6040 - val_accuracy: 0.1069 - val_loss: 1.5292 - learning_rate: 5.0000e-04\n",
      "Epoch 11/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.5945\n",
      "Epoch 11: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 1.6009 - val_accuracy: 0.1069 - val_loss: 1.5344 - learning_rate: 5.0000e-04\n",
      "Epoch 12/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.5946\n",
      "Epoch 12: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 1.5994 - val_accuracy: 0.1069 - val_loss: 1.5370 - learning_rate: 5.0000e-04\n",
      "Epoch 13/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.5974\n",
      "Epoch 13: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 1.6000 - val_accuracy: 0.1069 - val_loss: 1.5372 - learning_rate: 5.0000e-04\n",
      "Epoch 14/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.5956\n",
      "Epoch 14: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 1.6039 - val_accuracy: 0.1069 - val_loss: 1.5338 - learning_rate: 5.0000e-04\n",
      "Epoch 15/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.5977\n",
      "Epoch 15: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 1.6021 - val_accuracy: 0.1069 - val_loss: 1.5334 - learning_rate: 5.0000e-04\n",
      "Epoch 16/40\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2293 - loss: 1.5959\n",
      "Epoch 16: val_accuracy did not improve from 0.10687\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 1.5986 - val_accuracy: 0.1069 - val_loss: 1.5373 - learning_rate: 5.0000e-04\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "âœ“ Phase 1 Selesai!\n",
      "âœ“ Best Validation Accuracy Phase 1: 0.1069\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 4. TRAINING PHASE 1 (WARM UP)\n",
    "# =================================================================================================\n",
    "# Tujuannya agar layer Dense baru beradaptasi dengan fitur dari ResNet sebelum ResNet-nya kita utak-atik.\n",
    "\n",
    "active_class_weights = CLASS_WEIGHTS if USE_CLASS_WEIGHTS else None\n",
    "\n",
    "print(f\"\\n[INFO] === PHASE 1: Training Head Only ({EPOCHS_PHASE_1} Epochs) ===\")\n",
    "if USE_CLASS_WEIGHTS:\n",
    "    print(f\"âœ“ Class Weights aktif: {CLASS_WEIGHTS}\")\n",
    "\n",
    "history_1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_PHASE_1,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=active_class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "p1_best_val_acc = max(history_1.history['val_accuracy'])\n",
    "print(f\"\\nâœ“ Phase 1 Selesai!\")\n",
    "print(f\"âœ“ Best Validation Accuracy Phase 1: {p1_best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3df74bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bobot terbaik dari Phase 1 berhasil dimuat.\n",
      "\n",
      "[INFO] === PHASE 2: Fine Tuning (Start Layer 40, 30 Epochs) ===\n",
      "âœ“ 129 layers di-unfreeze untuk fine-tuning\n",
      "Epoch 17/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2313 - loss: 5.9705\n",
      "Epoch 17: val_accuracy improved from 0.10687 to 0.20611, saving model to best_resnet18_cbam_aflatoxin.keras\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - accuracy: 0.2592 - loss: 3.9704 - val_accuracy: 0.2061 - val_loss: 1.4163 - learning_rate: 1.0000e-04\n",
      "Epoch 18/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2561 - loss: 1.7744\n",
      "Epoch 18: val_accuracy did not improve from 0.20611\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3s/step - accuracy: 0.2908 - loss: 1.7072 - val_accuracy: 0.2061 - val_loss: 1.3859 - learning_rate: 1.0000e-04\n",
      "Epoch 19/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3039 - loss: 1.5716\n",
      "Epoch 19: val_accuracy did not improve from 0.20611\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3s/step - accuracy: 0.3200 - loss: 1.5821 - val_accuracy: 0.2061 - val_loss: 1.3719 - learning_rate: 1.0000e-04\n",
      "Epoch 20/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3643 - loss: 1.4756\n",
      "Epoch 20: val_accuracy did not improve from 0.20611\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 3s/step - accuracy: 0.3892 - loss: 1.4628 - val_accuracy: 0.2061 - val_loss: 1.3646 - learning_rate: 1.0000e-04\n",
      "Epoch 21/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4049 - loss: 1.4014\n",
      "Epoch 21: val_accuracy did not improve from 0.20611\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 3s/step - accuracy: 0.4400 - loss: 1.3518 - val_accuracy: 0.2061 - val_loss: 1.3712 - learning_rate: 1.0000e-04\n",
      "Epoch 22/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4502 - loss: 1.2403\n",
      "Epoch 22: val_accuracy did not improve from 0.20611\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 4s/step - accuracy: 0.4850 - loss: 1.2151 - val_accuracy: 0.2061 - val_loss: 1.4434 - learning_rate: 1.0000e-04\n",
      "Epoch 23/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4891 - loss: 1.1303\n",
      "Epoch 23: val_accuracy did not improve from 0.20611\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 3s/step - accuracy: 0.5167 - loss: 1.0935 - val_accuracy: 0.2061 - val_loss: 1.5901 - learning_rate: 1.0000e-04\n",
      "Epoch 24/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5703 - loss: 1.0248\n",
      "Epoch 24: val_accuracy did not improve from 0.20611\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 3s/step - accuracy: 0.5883 - loss: 0.9784 - val_accuracy: 0.2061 - val_loss: 1.7403 - learning_rate: 1.0000e-04\n",
      "Epoch 25/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6046 - loss: 0.9727\n",
      "Epoch 25: val_accuracy did not improve from 0.20611\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 3s/step - accuracy: 0.6100 - loss: 0.9441 - val_accuracy: 0.2061 - val_loss: 1.9105 - learning_rate: 1.0000e-04\n",
      "Epoch 26/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1524s/step - accuracy: 0.6225 - loss: 0.8598   \n",
      "Epoch 26: val_accuracy did not improve from 0.20611\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56382s\u001b[0m 1524s/step - accuracy: 0.6333 - loss: 0.8607 - val_accuracy: 0.2061 - val_loss: 2.1102 - learning_rate: 1.0000e-04\n",
      "Epoch 27/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6546 - loss: 0.8151\n",
      "Epoch 27: val_accuracy did not improve from 0.20611\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 4s/step - accuracy: 0.6600 - loss: 0.8198 - val_accuracy: 0.2061 - val_loss: 2.1289 - learning_rate: 1.0000e-04\n",
      "Epoch 28/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6771 - loss: 0.7776\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.20611\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 5s/step - accuracy: 0.6817 - loss: 0.7656 - val_accuracy: 0.2061 - val_loss: 2.1850 - learning_rate: 1.0000e-04\n",
      "Epoch 29/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7002 - loss: 0.6734\n",
      "Epoch 29: val_accuracy improved from 0.20611 to 0.25191, saving model to best_resnet18_cbam_aflatoxin.keras\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 4s/step - accuracy: 0.7242 - loss: 0.6487 - val_accuracy: 0.2519 - val_loss: 1.5988 - learning_rate: 5.0000e-05\n",
      "Epoch 30/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7545 - loss: 0.5417\n",
      "Epoch 30: val_accuracy improved from 0.25191 to 0.40458, saving model to best_resnet18_cbam_aflatoxin.keras\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 4s/step - accuracy: 0.7842 - loss: 0.5076 - val_accuracy: 0.4046 - val_loss: 1.2929 - learning_rate: 5.0000e-05\n",
      "Epoch 31/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7917 - loss: 0.4717\n",
      "Epoch 31: val_accuracy improved from 0.40458 to 0.47328, saving model to best_resnet18_cbam_aflatoxin.keras\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - accuracy: 0.8158 - loss: 0.4454 - val_accuracy: 0.4733 - val_loss: 1.1421 - learning_rate: 5.0000e-05\n",
      "Epoch 32/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8014 - loss: 0.4586\n",
      "Epoch 32: val_accuracy did not improve from 0.47328\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 4s/step - accuracy: 0.8242 - loss: 0.4223 - val_accuracy: 0.4122 - val_loss: 1.1554 - learning_rate: 5.0000e-05\n",
      "Epoch 33/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8285 - loss: 0.4096\n",
      "Epoch 33: val_accuracy did not improve from 0.47328\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 4s/step - accuracy: 0.8467 - loss: 0.3964 - val_accuracy: 0.4198 - val_loss: 1.2669 - learning_rate: 5.0000e-05\n",
      "Epoch 34/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8215 - loss: 0.3908\n",
      "Epoch 34: val_accuracy did not improve from 0.47328\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 4s/step - accuracy: 0.8408 - loss: 0.3743 - val_accuracy: 0.4122 - val_loss: 1.5733 - learning_rate: 5.0000e-05\n",
      "Epoch 35/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8549 - loss: 0.3672\n",
      "Epoch 35: val_accuracy improved from 0.47328 to 0.49618, saving model to best_resnet18_cbam_aflatoxin.keras\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3s/step - accuracy: 0.8725 - loss: 0.3404 - val_accuracy: 0.4962 - val_loss: 1.5895 - learning_rate: 5.0000e-05\n",
      "Epoch 36/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8731 - loss: 0.3192\n",
      "Epoch 36: val_accuracy improved from 0.49618 to 0.53435, saving model to best_resnet18_cbam_aflatoxin.keras\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3s/step - accuracy: 0.8875 - loss: 0.2972 - val_accuracy: 0.5344 - val_loss: 1.4196 - learning_rate: 5.0000e-05\n",
      "Epoch 37/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9086 - loss: 0.2456\n",
      "Epoch 37: val_accuracy did not improve from 0.53435\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 3s/step - accuracy: 0.9225 - loss: 0.2181 - val_accuracy: 0.4809 - val_loss: 1.7396 - learning_rate: 5.0000e-05\n",
      "Epoch 38/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9211 - loss: 0.2280\n",
      "Epoch 38: val_accuracy did not improve from 0.53435\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 3s/step - accuracy: 0.9300 - loss: 0.2110 - val_accuracy: 0.4885 - val_loss: 1.7077 - learning_rate: 5.0000e-05\n",
      "Epoch 39/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9154 - loss: 0.2155\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 39: val_accuracy did not improve from 0.53435\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 3s/step - accuracy: 0.9275 - loss: 0.2073 - val_accuracy: 0.4504 - val_loss: 1.9403 - learning_rate: 5.0000e-05\n",
      "Epoch 40/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9088 - loss: 0.2457\n",
      "Epoch 40: val_accuracy did not improve from 0.53435\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 3s/step - accuracy: 0.9117 - loss: 0.2362 - val_accuracy: 0.4809 - val_loss: 1.8925 - learning_rate: 2.5000e-05\n",
      "Epoch 41/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9349 - loss: 0.1749\n",
      "Epoch 41: val_accuracy did not improve from 0.53435\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3s/step - accuracy: 0.9475 - loss: 0.1588 - val_accuracy: 0.5191 - val_loss: 1.9009 - learning_rate: 2.5000e-05\n",
      "Epoch 42/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9548 - loss: 0.1329\n",
      "Epoch 42: val_accuracy did not improve from 0.53435\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3s/step - accuracy: 0.9625 - loss: 0.1204 - val_accuracy: 0.5267 - val_loss: 1.9974 - learning_rate: 2.5000e-05\n",
      "Epoch 43/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9549 - loss: 0.1148\n",
      "Epoch 43: val_accuracy did not improve from 0.53435\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 3s/step - accuracy: 0.9742 - loss: 0.0903 - val_accuracy: 0.5191 - val_loss: 2.1786 - learning_rate: 2.5000e-05\n",
      "Epoch 44/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9818 - loss: 0.0829\n",
      "Epoch 44: val_accuracy did not improve from 0.53435\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 3s/step - accuracy: 0.9883 - loss: 0.0673 - val_accuracy: 0.5267 - val_loss: 2.1581 - learning_rate: 2.5000e-05\n",
      "Epoch 45/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9829 - loss: 0.0612\n",
      "Epoch 45: val_accuracy improved from 0.53435 to 0.54198, saving model to best_resnet18_cbam_aflatoxin.keras\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 4s/step - accuracy: 0.9850 - loss: 0.0617 - val_accuracy: 0.5420 - val_loss: 2.1984 - learning_rate: 2.5000e-05\n",
      "Epoch 46/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9923 - loss: 0.0536\n",
      "Epoch 46: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 5s/step - accuracy: 0.9942 - loss: 0.0476 - val_accuracy: 0.5191 - val_loss: 2.2299 - learning_rate: 2.5000e-05\n",
      "Epoch 47/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9943 - loss: 0.0327\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 47: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 4s/step - accuracy: 0.9975 - loss: 0.0307 - val_accuracy: 0.5115 - val_loss: 2.3979 - learning_rate: 2.5000e-05\n",
      "Epoch 48/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9994 - loss: 0.0331\n",
      "Epoch 48: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 3s/step - accuracy: 0.9983 - loss: 0.0327 - val_accuracy: 0.5267 - val_loss: 2.3874 - learning_rate: 1.2500e-05\n",
      "Epoch 49/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9971 - loss: 0.0274\n",
      "Epoch 49: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3s/step - accuracy: 0.9950 - loss: 0.0317 - val_accuracy: 0.5267 - val_loss: 2.4335 - learning_rate: 1.2500e-05\n",
      "Epoch 50/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9980 - loss: 0.0328\n",
      "Epoch 50: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 3s/step - accuracy: 0.9983 - loss: 0.0301 - val_accuracy: 0.5267 - val_loss: 2.5157 - learning_rate: 1.2500e-05\n",
      "Epoch 51/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9963 - loss: 0.0337\n",
      "Epoch 51: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.9983 - loss: 0.0265 - val_accuracy: 0.5267 - val_loss: 2.5604 - learning_rate: 1.2500e-05\n",
      "Epoch 52/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9973 - loss: 0.0275\n",
      "Epoch 52: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 3s/step - accuracy: 0.9983 - loss: 0.0260 - val_accuracy: 0.5420 - val_loss: 2.5051 - learning_rate: 1.2500e-05\n",
      "Epoch 53/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9980 - loss: 0.0258\n",
      "Epoch 53: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 3s/step - accuracy: 0.9975 - loss: 0.0254 - val_accuracy: 0.5267 - val_loss: 2.6344 - learning_rate: 1.2500e-05\n",
      "Epoch 54/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9993 - loss: 0.0233\n",
      "Epoch 54: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 3s/step - accuracy: 0.9992 - loss: 0.0203 - val_accuracy: 0.5344 - val_loss: 2.6897 - learning_rate: 1.2500e-05\n",
      "Epoch 55/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9946 - loss: 0.0260\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 55: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 3s/step - accuracy: 0.9975 - loss: 0.0243 - val_accuracy: 0.5191 - val_loss: 2.7029 - learning_rate: 1.2500e-05\n",
      "Epoch 56/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9953 - loss: 0.0243\n",
      "Epoch 56: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 3s/step - accuracy: 0.9958 - loss: 0.0249 - val_accuracy: 0.5267 - val_loss: 2.7308 - learning_rate: 6.2500e-06\n",
      "Epoch 57/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9987 - loss: 0.0200\n",
      "Epoch 57: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 3s/step - accuracy: 0.9983 - loss: 0.0200 - val_accuracy: 0.5344 - val_loss: 2.7504 - learning_rate: 6.2500e-06\n",
      "Epoch 58/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9974 - loss: 0.0227\n",
      "Epoch 58: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 3s/step - accuracy: 0.9967 - loss: 0.0231 - val_accuracy: 0.5115 - val_loss: 2.8254 - learning_rate: 6.2500e-06\n",
      "Epoch 59/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9998 - loss: 0.0165\n",
      "Epoch 59: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 3s/step - accuracy: 0.9992 - loss: 0.0171 - val_accuracy: 0.5267 - val_loss: 2.7991 - learning_rate: 6.2500e-06\n",
      "Epoch 60/70\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0155\n",
      "Epoch 60: val_accuracy did not improve from 0.54198\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.5420 - val_loss: 2.8081 - learning_rate: 6.2500e-06\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "\n",
      "âœ“ Phase 2 Selesai!\n",
      "âœ“ Best Validation Accuracy Phase 2: 0.5420\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 5. TRAINING PHASE 2 (FINE TUNING)\n",
    "# =================================================================================================\n",
    "# Sekarang kita cairkan sebagian layer ResNet18 untuk menyesuaikan fitur spesifik\n",
    "\n",
    "# --- LANGKAH PENTING: MUAT BOBOT TERBAIK DARI FASE 1 ---\n",
    "try:\n",
    "    model.load_weights(MODEL_SAVE_PATH)\n",
    "    print(\"âœ… Bobot terbaik dari Phase 1 berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Peringatan: Gagal memuat bobot dari {MODEL_SAVE_PATH}. Error: {e}\")\n",
    "    print(\"   Melanjutkan dengan bobot terakhir Phase 1.\")\n",
    "    \n",
    "print(f\"\\n[INFO] === PHASE 2: Fine Tuning (Start Layer {FINE_TUNE_AT}, {EPOCHS_PHASE_2} Epochs) ===\")\n",
    "\n",
    "total_epochs = EPOCHS_PHASE_1 + EPOCHS_PHASE_2\n",
    "base_model.trainable = True  # Unfreeze base model\n",
    "\n",
    "# Freeze ulang layer-layer awal (Low-level features seperti garis/sudut biasanya sudah bagus)\n",
    "# Kita hanya ingin melatih layer-layer akhir (High-level features)\n",
    "for layer in base_model.layers[:FINE_TUNE_AT]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Hitung jumlah layer yang di-unfreeze\n",
    "trainable_count = sum([1 for layer in base_model.layers if layer.trainable])\n",
    "print(f\"âœ“ {trainable_count} layers di-unfreeze untuk fine-tuning\")\n",
    "\n",
    "# Compile ulang wajib dilakukan setelah mengubah trainable status\n",
    "# Gunakan LR yang lebih kecil untuk fine-tuning\n",
    "if OPTIMIZER_NAME.lower() == 'adam':\n",
    "    opt_ft = Adam(learning_rate=LR_PHASE_2)\n",
    "elif OPTIMIZER_NAME.lower() == 'sgd':\n",
    "    opt_ft = SGD(learning_rate=LR_PHASE_2, momentum=0.9)\n",
    "elif OPTIMIZER_NAME.lower() == 'adamw':\n",
    "    opt_ft = AdamW(learning_rate=LR_PHASE_2)\n",
    "else:\n",
    "    opt_ft = RMSprop(learning_rate=LR_PHASE_2)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt_ft, \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "history_2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    initial_epoch=len(history_1.history['loss']),\n",
    "    epochs=total_epochs,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=active_class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "p2_best_val_acc = max(history_2.history['val_accuracy'])\n",
    "print(f\"\\nâœ“ Phase 2 Selesai!\")\n",
    "print(f\"âœ“ Best Validation Accuracy Phase 2: {p2_best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241dc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Melakukan Evaluasi Menyeluruh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PDE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 166 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Best model loaded from best_resnet18_cbam_aflatoxin.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 437ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 28  0  0]\n",
      " [ 0 55  0  0]\n",
      " [ 0 35  0  0]\n",
      " [ 0 14  0  0]]\n",
      "============================================================\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kelas 1     0.0000    0.0000    0.0000        28\n",
      "     Kelas 2     0.4167    1.0000    0.5882        55\n",
      "     Kelas 3     0.0000    0.0000    0.0000        35\n",
      "     Kelas 4     0.0000    0.0000    0.0000        14\n",
      "\n",
      "    accuracy                         0.4167       132\n",
      "   macro avg     0.1042    0.2500    0.1471       132\n",
      "weighted avg     0.1736    0.4167    0.2451       132\n",
      "\n",
      "âœ… Akurasi Test Akhir: 41.67%\n",
      "âœ… Rata-rata Confidence: 25.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PDE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PDE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PDE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PDE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PDE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PDE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ–¼ï¸ Gambar Confusion Matrix tersimpan di: history_plots\\cm_resnet18_cbam_20260203_160432_Acc41.7.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 6. EVALUASI DAN METRIK (OTOMATIS)\n",
    "# =================================================================================================\n",
    "print(\"\\n[INFO] Melakukan Evaluasi Menyeluruh...\")\n",
    "\n",
    "# Load best model\n",
    "try:\n",
    "    model.load_weights(MODEL_SAVE_PATH)\n",
    "    print(f\"âœ“ Best model loaded from {MODEL_SAVE_PATH}\")\n",
    "except:\n",
    "    print(\"âš ï¸ Using current model weights\")\n",
    "\n",
    "# Prediksi (menghasilkan probabilitas, misal [0.1, 0.8, 0.05, 0.05])\n",
    "Y_pred_probs = model.predict(test_ds, verbose=1)\n",
    "\n",
    "# Ambil kelas dengan probabilitas tertinggi\n",
    "y_pred = np.argmax(Y_pred_probs, axis=1)\n",
    "\n",
    "# Label asli (Ground Truth)\n",
    "y_true_onehot = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "y_true = np.argmax(y_true_onehot, axis=1)\n",
    "\n",
    "class_names = ['Kelas 1', 'Kelas 2', 'Kelas 3', 'Kelas 4']\n",
    "\n",
    "# --- Metrik 1: Akurasi Global ---\n",
    "test_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# --- Metrik 2: Confusion Matrix ---\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_str = str(cm.tolist())\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# --- Metrik 3: Confidence Statistics ---\n",
    "confidence_scores = np.max(Y_pred_probs, axis=1)\n",
    "avg_conf = np.mean(confidence_scores)\n",
    "min_conf = np.min(confidence_scores)\n",
    "std_conf = np.std(confidence_scores)\n",
    "\n",
    "# --- Metrik 4: Precision, Recall, F1 Per Kelas ---\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, digits=4, output_dict=True)\n",
    "print(\"=\" * 60)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "print(f\"âœ… Akurasi Test Akhir: {test_acc*100:.2f}%\")\n",
    "print(f\"âœ… Rata-rata Confidence: {avg_conf*100:.2f}%\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plot_folder = \"history_plots_RN18\" \n",
    "if not os.path.exists(plot_folder):\n",
    "    os.makedirs(plot_folder)\n",
    "\n",
    "current_time_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "plot_filename = f\"cm_resnet18_cbam_{current_time_str}_Acc{test_acc*100:.1f}.png\"\n",
    "plot_filepath = os.path.join(plot_folder, plot_filename)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            annot_kws={\"size\": 14})\n",
    "plt.title(f'Confusion Matrix - ResNet18+CBAM (Acc: {test_acc*100:.2f}%)')\n",
    "plt.ylabel('Actual Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(plot_filepath, dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nğŸ–¼ï¸ Gambar Confusion Matrix tersimpan di: {plot_filepath}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8b93ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SAVE] File log baru dibuat: experiment_log_resnet18_cbam.csv\n",
      "============================================================\n",
      "PROSES SELESAI. SILAKAN UBAH PARAMETER DI ATAS UNTUK PERCOBAAN BERIKUTNYA.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 7. SISTEM PENYIMPANAN LOG (AUTO-CSV)\n",
    "# =================================================================================================\n",
    "# Bagian ini yang akan menyimpan \"Jejak Percobaan\" kamu selamanya.\n",
    "\n",
    "# Dictionary data untuk satu baris CSV\n",
    "log_data = {\n",
    "    # Waktu\n",
    "    \"Timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \n",
    "    # Model Info\n",
    "    \"Model\": f\"ResNet18 + CBAM ({USE_CBAM})\",\n",
    "    \n",
    "    # Parameter Setup\n",
    "    \"Optimizer\": OPTIMIZER_NAME,\n",
    "    \"Batch_Size\": BATCH_SIZE,\n",
    "    \"Layer_Config\": str(LAYER_CONFIG),\n",
    "    \"Dropout\": DROPOUT_RATE,\n",
    "    \"Fine_Tune_At\": FINE_TUNE_AT,\n",
    "    \"Use_CBAM\": USE_CBAM,\n",
    "    \"SE_Reduction_Ratio\": SE_REDUCTION_RATIO,\n",
    "    \"Spatial_Kernel\": SPATIAL_KERNEL_SIZE,\n",
    "    \n",
    "    # Parameter Training\n",
    "    \"LR_Phase_1\": LR_PHASE_1,\n",
    "    \"Epochs_P1\": EPOCHS_PHASE_1,\n",
    "    \"LR_Phase_2\": LR_PHASE_2,\n",
    "    \"Epochs_P2\": EPOCHS_PHASE_2,\n",
    "    \"Label_Smoothing\": LABEL_SMOOTHING,\n",
    "    \"Use_Class_Weights\": USE_CLASS_WEIGHTS,\n",
    "    \n",
    "    # Hasil Evaluasi Global\n",
    "    \"Accuracy\": round(test_acc, 4),\n",
    "    \"Val_Acc_P1\": round(p1_best_val_acc, 4),\n",
    "    \"Val_Acc_P2\": round(p2_best_val_acc, 4),\n",
    "    \"Avg_Confidence\": round(avg_conf, 4),\n",
    "    \"Min_Confidence\": round(min_conf, 4),\n",
    "    \"Std_Confidence\": round(std_conf, 4),\n",
    "    \"Confusion_Matrix\": cm_str\n",
    "}\n",
    "\n",
    "# Loop otomatis untuk mengambil Precision/Recall/F1 tiap kelas\n",
    "for label in class_names:\n",
    "    metrics = report[label]\n",
    "    log_data[f\"Class_{label}_Prec\"] = round(metrics['precision'], 4)\n",
    "    log_data[f\"Class_{label}_Rec\"] = round(metrics['recall'], 4)\n",
    "    log_data[f\"Class_{label}_F1\"] = round(metrics['f1-score'], 4)\n",
    "\n",
    "# Buat DataFrame (1 baris)\n",
    "df_new_log = pd.DataFrame([log_data])\n",
    "\n",
    "# Logika Penyimpanan: Append jika file ada, Write jika belum ada\n",
    "if not os.path.exists(LOG_FILE_PATH):\n",
    "    df_new_log.to_csv(LOG_FILE_PATH, index=False)\n",
    "    print(f\"\\n[SAVE] File log baru dibuat: {LOG_FILE_PATH}\")\n",
    "else:\n",
    "    df_new_log.to_csv(LOG_FILE_PATH, mode='a', header=False, index=False)\n",
    "    print(f\"\\n[SAVE] Hasil percobaan berhasil ditambahkan ke: {LOG_FILE_PATH}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PROSES SELESAI. SILAKAN UBAH PARAMETER DI ATAS UNTUK PERCOBAAN BERIKUTNYA.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49a4404d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Tidak ada CBAM spatial attention layer ditemukan.\n",
      "   Pastikan USE_CBAM = True saat membangun model.\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# 8. VISUALISASI CBAM ATTENTION MAP (OPSIONAL)\n",
    "# =================================================================================================\n",
    "# Visualisasi ini menunjukkan \"di mana\" model fokus saat membuat prediksi\n",
    "# Sangat berguna untuk memahami apakah model melihat area fluorescence yang relevan\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_cbam_attention(model, test_ds, num_samples=4):\n",
    "    \"\"\"\n",
    "    Visualisasi spatial attention map dari CBAM\n",
    "    Menunjukkan area mana yang difokuskan model\n",
    "    \"\"\"\n",
    "    # Cari layer spatial attention terakhir (dari layer4)\n",
    "    spatial_layers = [l for l in model.layers if 'sa_conv' in l.name or 'sp_sa_conv' in l.name]\n",
    "    \n",
    "    if not spatial_layers:\n",
    "        print(\"âš ï¸ Tidak ada CBAM spatial attention layer ditemukan.\")\n",
    "        print(\"   Pastikan USE_CBAM = True saat membangun model.\")\n",
    "        return\n",
    "    \n",
    "    # Ambil layer spatial attention terakhir\n",
    "    target_layer = spatial_layers[-1]\n",
    "    print(f\"ğŸ“ Menggunakan attention layer: {target_layer.name}\")\n",
    "    \n",
    "    # Buat model untuk ekstrak attention map\n",
    "    attention_model = tf.keras.Model(\n",
    "        inputs=model.input,\n",
    "        outputs=[target_layer.output, model.output]\n",
    "    )\n",
    "    \n",
    "    # Ambil beberapa sample dari test set\n",
    "    images_list = []\n",
    "    labels_list = []\n",
    "    for imgs, lbls in test_ds:\n",
    "        images_list.append(imgs.numpy())\n",
    "        labels_list.append(lbls.numpy())\n",
    "        if len(images_list) * imgs.shape[0] >= num_samples:\n",
    "            break\n",
    "    \n",
    "    images = np.concatenate(images_list, axis=0)[:num_samples]\n",
    "    labels = np.concatenate(labels_list, axis=0)[:num_samples]\n",
    "    \n",
    "    # Dapatkan attention maps dan prediksi\n",
    "    attention_maps, predictions = attention_model.predict(images, verbose=0)\n",
    "    \n",
    "    class_names = ['Kelas 1', 'Kelas 2', 'Kelas 3', 'Kelas 4']\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        true_label = np.argmax(labels[i])\n",
    "        pred_label = np.argmax(predictions[i])\n",
    "        confidence = np.max(predictions[i]) * 100\n",
    "        \n",
    "        # Original image\n",
    "        axes[i, 0].imshow(images[i])\n",
    "        axes[i, 0].set_title(f'Original\\nTrue: {class_names[true_label]}', fontsize=11)\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Attention map (resize ke ukuran gambar)\n",
    "        att_map = attention_maps[i, :, :, 0]\n",
    "        att_resized = tf.image.resize(\n",
    "            att_map[..., np.newaxis], \n",
    "            (224, 224), \n",
    "            method='bilinear'\n",
    "        ).numpy()[:, :, 0]\n",
    "        \n",
    "        axes[i, 1].imshow(att_resized, cmap='jet')\n",
    "        axes[i, 1].set_title(f'Spatial Attention Map', fontsize=11)\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Overlay\n",
    "        axes[i, 2].imshow(images[i])\n",
    "        axes[i, 2].imshow(att_resized, cmap='jet', alpha=0.4)\n",
    "        correct = \"âœ“\" if true_label == pred_label else \"âœ—\"\n",
    "        axes[i, 2].set_title(\n",
    "            f'{correct} Pred: {class_names[pred_label]} ({confidence:.1f}%)', \n",
    "            fontsize=11,\n",
    "            color='green' if true_label == pred_label else 'red'\n",
    "        )\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.suptitle('CBAM Spatial Attention Visualization', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    plot_folder = \"history_plots\"\n",
    "    if not os.path.exists(plot_folder):\n",
    "        os.makedirs(plot_folder)\n",
    "    att_filename = f\"cbam_attention_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "    plt.savefig(os.path.join(plot_folder, att_filename), dpi=200, bbox_inches='tight')\n",
    "    print(f\"\\nğŸ–¼ï¸ Attention map tersimpan di: {plot_folder}/{att_filename}\")\n",
    "    plt.show()\n",
    "\n",
    "# Jalankan visualisasi\n",
    "if USE_CBAM:\n",
    "    visualize_cbam_attention(model, test_ds, num_samples=4)\n",
    "else:\n",
    "    print(\"â„¹ï¸ CBAM tidak aktif. Set USE_CBAM = True untuk visualisasi attention.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519abea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
